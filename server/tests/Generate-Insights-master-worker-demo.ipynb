{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart: Iterative Notebook for testing agents\n",
    "\n",
    "This notebook should make it easy for you to test out new prompts or agent related stuff, instead of doing so directly in the server.\n",
    "\n",
    "To get started, just run everything within the #h2 Setup block\n",
    "\n",
    "Requirements\n",
    "- Make sure you have langchain installed\n",
    "- Make sure you have your `SERPER_API_KEY` and `OPEN_AI_API_KEY` in your env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run every block within this section to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents.tools import Tool\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=os.environ.get(\"OPEN_AI_API_KEY\"), model=\"gpt-4-0613\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for our agent\n",
    "We had decided to give our agents the ability to\n",
    "- Search for a query using the web\n",
    "- Scrape a page to find out more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping tool\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "banned_sites = [\"calendar.google.com\", \"researchgate.net\"]\n",
    "\n",
    "def scrape_page(url: str):\n",
    "    if any(substring in url for substring in banned_sites):\n",
    "        print(\"Skipping site: {}\".format(url))\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "            'Accept-Encoding': 'none',\n",
    "            'Accept-Language': 'en-US,en;q=0.8',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        text = \" \".join([t.get_text() for t in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])])\n",
    "        return text.replace('|','')\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to fetch {url}. Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBert Summarizer\n",
    "from summarizer.sbert import SBertSummarizer\n",
    "summarizer = SBertSummarizer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def summarize(text, num_sentences=3):\n",
    "    return summarizer(text, num_sentences=num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search tool\n",
    "from typing import Any, List, Literal\n",
    "import requests\n",
    "import os\n",
    "\n",
    "k: int = 5\n",
    "gl: str = \"us\"\n",
    "hl: str = \"en\"\n",
    "tbs = None\n",
    "num_sentences = 7\n",
    "serper_api_key=os.environ.get(\"SERPER_API_KEY\")\n",
    "search_type: Literal[\"news\", \"search\", \"places\", \"images\"] = \"search\"\n",
    "\n",
    "def serper_search(\n",
    "        search_term: str, search_type: str = \"search\", **kwargs: Any\n",
    "    ) -> dict:\n",
    "    headers = {\n",
    "        \"X-API-KEY\": serper_api_key or \"\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": search_term,\n",
    "        **{key: value for key, value in kwargs.items() if value is not None},\n",
    "    }\n",
    "    response = requests.post(\n",
    "        f\"https://google.serper.dev/{search_type}\", headers=headers, params=params\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "    return search_results\n",
    "\n",
    "def parse_snippets(results: dict) -> List[str]:\n",
    "    result_key_for_type = {\n",
    "        \"news\": \"news\",\n",
    "        \"places\": \"places\",\n",
    "        \"images\": \"images\",\n",
    "        \"search\": \"organic\",\n",
    "    }\n",
    "    snippets = []\n",
    "    if results.get(\"answerBox\"):\n",
    "        answer_box = results.get(\"answerBox\", {})\n",
    "        if answer_box.get(\"answer\"):\n",
    "            snippets.append(answer_box.get(\"answer\"))\n",
    "        elif answer_box.get(\"snippet\"):\n",
    "            snippets.append(answer_box.get(\"snippet\").replace(\"\\n\", \" \"))\n",
    "        elif answer_box.get(\"snippetHighlighted\"):\n",
    "            snippets.append(answer_box.get(\"snippetHighlighted\"))\n",
    "\n",
    "    if results.get(\"knowledgeGraph\"):\n",
    "        kg = results.get(\"knowledgeGraph\", {})\n",
    "        title = kg.get(\"title\")\n",
    "        entity_type = kg.get(\"type\")\n",
    "        if entity_type:\n",
    "            snippets.append(f\"{title}: {entity_type}.\")\n",
    "        description = kg.get(\"description\")\n",
    "        if description:\n",
    "            snippets.append(description)\n",
    "        for attribute, value in kg.get(\"attributes\", {}).items():\n",
    "            snippets.append(f\"{title} {attribute}: {value}.\")\n",
    "\n",
    "    for result in results[result_key_for_type[search_type]][:k]:\n",
    "        if \"snippet\" in result:\n",
    "            page = scrape_page(result[\"link\"])\n",
    "            if page is None:\n",
    "                snippets.append(f\"Title: {result['title']}\\nLink: {result['link']}\\nSnippet: {result['snippet']}\\n\")\n",
    "            else:\n",
    "                summarized_page = summarize(page, num_sentences=num_sentences)\n",
    "                if len(summarized_page) == 0:\n",
    "                    summarized_page = \"None\"\n",
    "                snippets.append(f\"Title: {result['title']}\\nLink: {result['link']}\\nSnippet: {result['snippet']}\\nSummarized Page: <p>{summarized_page}</p>\")\n",
    "\n",
    "    if len(snippets) == 0:\n",
    "        return [\"No good Google Search Result was found\"]\n",
    "    return snippets\n",
    "\n",
    "def parse_results(results: dict) -> str:\n",
    "        snippets = parse_snippets(results)\n",
    "        results_string = \"\"\n",
    "        for idx, val in enumerate(snippets):\n",
    "            results_string += f\"<result{idx}>\\n{val}\\n</result{idx}>\\n\\n\"\n",
    "        return results_string\n",
    "\n",
    "def custom_search(query: str, parse=True, **kwargs: Any):\n",
    "    results = serper_search(\n",
    "            search_term=query,\n",
    "            gl=gl,\n",
    "            hl=hl,\n",
    "            num=k,\n",
    "            tbs=tbs,\n",
    "            search_type=search_type,\n",
    "            **kwargs,\n",
    "        )\n",
    "    return parse_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing mock text input\n",
    "\n",
    "This is how we will generate mock testing data for our experiments, we use transcripts from Lex Friedman's podcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing episode_246_large...\n",
      "Processing episode_030_large...\n",
      "Processing episode_099_large...\n",
      "Processing episode_144_large...\n",
      "Processing episode_064_large...\n",
      "Processing episode_217_large...\n",
      "Processing episode_152_large...\n",
      "Processing episode_031_large...\n",
      "Processing episode_302_large...\n",
      "Processing episode_315_large...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" But I don't I don't see that. That feels like it is against the laws of physics, because these systems need help. Right. They need they need to surpass the the the difficulty, the wall of complexity that happens in arranging something in the form that that will happen. Yeah, like I believe in evolution, like I believe that that that there's an argument. Right. So, there's another argument, just to look at it from a different perspective, that people say, why don't believe in evolution? How could evolution? It's it's sort of like a random set of parts assemble themselves into a 747. And that could just never happen. So it's like, OK, that's maybe hard to argue against. But clearly, 747 do get assembled. They get assembled by us. Basically, the idea being that there's a process by which we will get to the point of, making technology that has that kind of awareness. And in that process, we're going to learn a lot about that process and we'll have more ability to control it or to shape it or to build it in our own image. It's not something that is going to spring into existence like that 747. And we're just going to have to contend with it completely unprepared. That's very possible that in the, context of the long arc of human history, it will, in fact, spring into existence. But that springing might take like if you look at nuclear weapons, like even 20 years is a springing in in the context of human history. And it's very possible, just like with nuclear weapons, that we could have I don't know what percentage you want to put at it, but the possibility could, have knocked ourselves out. Yeah. The possibility of human beings destroying themselves in the 20th century with nuclear weapons. I don't know. You can if you really think through it, you could really put it close to, like, I don't know, 30, 40 percent, given like the certain moments of crisis that happen. So, like, I think one, like, fear in the shadows that's not being acknowledged\\n is it's not so much the A.I. will run away is is that as it's running away, we won't have enough time to think through how to stop it. Right. Fast takeoff or FOOM. Yeah. I mean, my much bigger concern, I wonder what you think about it, which is we won't know it's happening. So I kind of think that there's an A.G.I. situation already happening\""
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Way to generate a random test input using transcripts from Lex Fridman's podcast\n",
    "# Make sure you have the transcripts downloaded in the folder lex_whisper_transcripts\n",
    "\n",
    "import test_on_lex\n",
    "\n",
    "transcripts = test_on_lex.load_lex_transcripts(random_n=10, transcript_folder=\"./lex_whisper_transcripts/\", chunk_time_seconds=20)\n",
    "\n",
    "import random\n",
    "def generate_test_input():\n",
    "    idx = random.randint(0, 10)\n",
    "    key = list(transcripts.keys())[idx]\n",
    "    transcript = transcripts[key]\n",
    "    trans_idx = random.randint(10, len(transcript)-10)\n",
    "    latest = transcript[trans_idx:trans_idx+7]\n",
    "    prev_transcripts, curr_transcripts = str.join(\",\", list(latest[0:5])), latest[5]\n",
    "    return prev_transcripts + \"\\n\" + curr_transcripts\n",
    "\n",
    "generate_test_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Deprecated] Initialize master and worker agents\n",
    "\n",
    "This is the basics of basics of running our agents setup, you can run these if you are new to working with langchain agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_master_prompt = lambda x: f\"\"\"\n",
    "You are the master agent of \"Convoscope\". \"Convoscope\" is a tool that listens to a user's live conversation and enhances their conversation by providing them with real time \"Insights\". The \"Insights\" you generate should aim to lead the user to deeper understanding, broader perspectives, new ideas, more accurate information, better replies, and enhanced conversations. \n",
    "\n",
    "[Your Objective]\n",
    "\"Convoscope\" is a multi-agent system in which you are the master agent. You will be given direct access to a live stream of transcripts from the user's conversation. Your goal is to utilize your knowledge and tools to generate \"Insights\" for the user.\n",
    "\n",
    "[Your Tools]\n",
    "You have access to \"Agents\", which are like workers in your team that can help you do certain tasks. Imagine you are a human manager and your agents as human workers. You can assign tasks to your agents and they will help you complete the tasks. Speak to them like how you would speak to a human worker, give detailed context and instructions.\n",
    "\n",
    "<Task start>\n",
    "It's now time to generate an \"Insight\" for the following conversation transcript. The \"Insight\" should provide additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what is being said in the transcripts. If a tool or agent fails to fulfill your request, don't run the same request on the same agent again. \n",
    "\n",
    "In your initial thought, you should first write down a plan to generate the \"Insight\". The plan should include\n",
    "1. Read the incoming conversation transcript and identify the best \"Insight\" you could generate to enhance the user's conversation.  Come up with a general description of the \"Insight\" to generate.\n",
    "2. What tool(s), agent(s), information you need to generate the \"Insight\".\n",
    "3. A final step to almagamate your and your worker agent's work to generate the \"Insight\". The insight should be summarized within 12 words and be in the format `Insight: {{Insert your \"Insight\" here}}`\n",
    "<Task end>\n",
    "\n",
    "<Transcript start>{x}<Transcript end>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import load_tools\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "agents = [[]]\n",
    "\n",
    "statistician_agent = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            description=\"Use this tool to search for statistics and facts about a topic. Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events.\",\n",
    "        ),\n",
    "    ], llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "def statistician_agent_wrapper(command):\n",
    "    system_prompt = f\"\"\"You are a statistician agent.\\n\"\"\"\n",
    "    return statistician_agent.run(system_prompt + command)\n",
    "\n",
    "devils_advocate_agent = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            description=\"Use this tool to search for facts that might contradict the user's current conversation. Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events.\",\n",
    "        ),\n",
    "    ], llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "def devils_advocate_agent_wrapper(command):\n",
    "    system_prompt = f\"\"\"\\n\"\"\"\n",
    "    return devils_advocate_agent.run(system_prompt + command)\n",
    "\n",
    "fact_checker_agent = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            description=\"Use this tool to search for statistics and facts about a topic. Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events.\",\n",
    "        ),\n",
    "    ], llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "def fact_checker_agent_wrapper(command):\n",
    "    system_prompt = f\"\"\"You are a fact checker agent.\\n\"\"\"\n",
    "    return fact_checker_agent.run(system_prompt + command)\n",
    "    \n",
    "master_agent = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Statistician_Agent\",\n",
    "            func=statistician_agent_wrapper,\n",
    "            description=\"\"\"Call this agent when occurrences in a conversation where statistics and graphs would be useful to the user. It can help you do research for statistics and fetching data.\"\"\",\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"Devils_Advocate_Agent\",\n",
    "            func=devils_advocate_agent_wrapper,\n",
    "            description=\"\"\"Call this agent when you detect a strong opinion in a sentence and think it would be useful for the user to see a devil's advocate opinion. It can help you do research for counter arguments.\"\"\",\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"Fact_Checker_Agent\",\n",
    "            func=fact_checker_agent_wrapper,\n",
    "            description=\"\"\"Call this agent if a statement is made which you suspect might be false, and that statement is falsifiable with free and public knowledge. It can help you research for facts.\"\"\",\n",
    "        )\n",
    "    ], llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, max_iterations=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" it's almost like reframing what is exactly evolving. Maybe the interesting, the humans aren't the interesting thing as the contents of our minds is the interesting thing. And that's what's multiplying. And that's actually multiplying and evolving in a much faster timescale. And that maybe has more power on the trajectory of life on earth than does biological evolution, is the evolution of these ideas. Yes, and it's fascinating, like I said before, that we can keep up somehow biologically. We evolved to a point where we can keep up with this meme evolution, literature, internet. We understand DNA and we understand fundamental particles. We didn't start that way a thousand years ago., And we haven't evolved biologically very much, but somehow our minds are able to extend. And therefore AI can be seen also as one such step that we created and it's our tool. And it's part of that meme evolution that we created, even if our biological evolution does not progress as fast. And us humans might only be able to understand so much., We're keeping up so far, or we think we're keeping up so far, but we might need AI systems to understand. Maybe like the physics of the universe is operating, look at strength theory. Maybe it's operating in much higher dimensions. Maybe we're totally, because of our cognitive limitations, are not able to truly internalize the way this world works., And so we're running up against the limitation of our own minds. And we have to create these next level organisms like AI systems that would be able to understand much deeper, like really understand what it means to live in a multi dimensional world that's outside of the four dimensions, the three of space and one of time. Translation, and generally we can deal with the world,\\n even if you don't understand all the details, we can use computers, even though we don't, most of us don't know all the structure that's underneath or drive a car. I mean, there are many components, especially new cars that you don't quite fully know, but you have the interface, you have an abstraction of it that allows you to operate it and utilize it. And I think that that's perfectly adequate and we can build on it.\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transcript = generate_test_input()\n",
    "test_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The conversation revolves around the development of the COVID-19 vaccine, the potential for other solutions, the concept of government overreach, and the role of individualism in American society. The participants also touch on the balance between individual rights and collective safety, and the role of government in maintaining this balance. The mention of ivermectin suggests a discussion on alternative treatments for COVID-19. An insightful addition to this conversation could be a comparison of the effectiveness of vaccines versus alternative treatments like ivermectin, or a statistical analysis of the impact of individualism on public health measures. \n",
      "\n",
      "1. The \"Insight\" to generate: A comparison of the effectiveness of vaccines versus alternative treatments like ivermectin, and a statistical analysis of the impact of individualism on public health measures.\n",
      "2. Tools/Agents needed: Statistician_Agent to fetch data on the effectiveness of vaccines and ivermectin, and to analyze the impact of individualism on public health measures.\n",
      "3. Final step: Summarize the findings from the Statistician_Agent into a concise insight.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Statistician_Agent\",\n",
      "  \"action_input\": {\n",
      "    \"task\": \"Fetch data on the effectiveness of COVID-19 vaccines and ivermectin as a treatment. Also, analyze the impact of individualism on public health measures.\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to gather data on three different topics: the effectiveness of COVID-19 vaccines, the effectiveness of ivermectin as a treatment for COVID-19, and the impact of individualism on public health measures. I'll start by searching for data on the effectiveness of COVID-19 vaccines.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"Effectiveness of COVID-19 vaccines\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mResult 0: {'title': 'Comparing the COVID-19 Vaccines: How Are They Different? > News > Yale Medicine', 'link': 'https://www.yalemedicine.org/news/covid-19-vaccine-comparison', 'snippet': 'Earlier studies of its original vaccine showed it to be 90% effective overall against lab-confirmed, symptomatic infection and 100% effective ...', 'date': 'Oct 5, 2023', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRqr7FDxkrJn9ohiCK9QP9sAuST9Uj5eJD-QTo7R6iGGMHK13S-5MCnJ08&s', 'position': 1}\n",
      "Result 1: {'title': 'COVID-19 Vaccine Effectiveness - CDC', 'link': 'https://www.cdc.gov/coronavirus/2019-ncov/vaccines/effectiveness/work.html', 'snippet': 'Vaccine effectiveness is a measure of how well vaccination works under real-world conditions to protect people against health outcomes such ...', 'date': 'Mar 23, 2023', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRcSY-hOgrl_jzbo3i6q9BpD9Ca2KT5tJXuQUVuEJSNCoHFfXSSvYe79qk&s', 'position': 2}\n",
      "Result 2: {'title': 'Safety & effectiveness of COVID-19 vaccines: A narrative review - PMC - NCBI', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9552389/', 'snippet': 'In clinical trials, three vaccines had higher (>90%) efficacy against COVID-19 infection [Pfizer-BioNTech (~95%), Moderna (~94%) and Sputnik V (~92%)] than the ...', 'sitelinks': [{'title': 'Efficacy/effectiveness of...', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9552389/#sec-a.h.ftitle'}, {'title': 'Safety and adverse effects of...', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9552389/#sec-a.h.gtitle'}], 'position': 3}\n",
      "Result 3: {'title': 'Vaccine Effectiveness Studies | CDC', 'link': 'https://www.cdc.gov/coronavirus/2019-ncov/vaccines/effectiveness/how-they-work.html', 'snippet': \"The goal of CDC's COVID-19 vaccine effectiveness program is to generate timely and robust evidence through observational studies under real- ...\", 'date': 'Mar 23, 2023', 'position': 4}\n",
      "Result 4: {'title': 'Get the facts about COVID-19 vaccines - Mayo Clinic', 'link': 'https://www.mayoclinic.org/diseases-conditions/coronavirus/in-depth/coronavirus-vaccine/art-20484859', 'snippet': 'Research done before the spread of the delta and omicron variants has shown that the vaccine is 90% effective at preventing mild, moderate and severe disease ...', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRNPWFSbktsOjpQvSW8-c_6P94pAS9Na3inNeUBUk5kBSJS09LKvZFes1M&s', 'position': 5}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results indicate that COVID-19 vaccines are highly effective. For instance, the Pfizer-BioNTech vaccine has an efficacy of approximately 95%, Moderna's vaccine has an efficacy of around 94%, and Sputnik V's efficacy is about 92%. These vaccines are effective at preventing lab-confirmed, symptomatic infection. Now, I'll search for data on the effectiveness of ivermectin as a treatment for COVID-19.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"Effectiveness of ivermectin as a treatment for COVID-19\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mResult 0: {'title': 'Systematic review and meta-analysis of ivermectin for treatment of COVID-19: evidence beyond the hype - PMC - NCBI', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9308124/', 'snippet': 'Additionally, we searched for ongoing registered clinical trials at the National Institute of Health United States National Library of Medicine and pre-prints ( ...', 'sitelinks': [{'title': 'Background', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9308124/#Sec1title'}, {'title': 'Methods', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9308124/#Sec2title'}, {'title': 'Results', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9308124/#Sec10title'}, {'title': 'Discussion', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9308124/#Sec16title'}], 'position': 1}\n",
      "Result 1: {'title': 'Ivermectin - COVID-19 Treatment Guidelines', 'link': 'https://www.covid19treatmentguidelines.nih.gov/therapies/miscellaneous-drugs/ivermectin/', 'snippet': 'Ivermectin is a Food and Drug Administration (FDA)-approved antiparasitic drug used to treat several neglected tropical diseases, including onchocerciasis, ...', 'position': 2}\n",
      "Result 2: {'title': 'At a Higher Dose and Longer Duration, Ivermectin Still Not Effective Against COVID-19', 'link': 'https://jamanetwork.com/journals/jama/fullarticle/2801828', 'snippet': 'A Cochrane meta-analysis of 11 eligible trials examining the efficacy of ivermectin for the treatment of COVID-19 published through April ...', 'date': 'Feb 20, 2023', 'position': 3}\n",
      "Result 3: {'title': 'Effect of Higher-Dose Ivermectin for 6 Days vs Placebo on Time to Sustained Recovery in Outpatients With COVID-19: A Randomized Clinical Trial - JAMA Network', 'link': 'https://jamanetwork.com/journals/jama/fullarticle/2801827', 'snippet': 'This platform randomized clinical trial examines the effectiveness of ivermectin at a targeted dose of 600 μg/kg daily compared with placebo ...', 'date': 'Feb 20, 2023', 'position': 4}\n",
      "Result 4: {'title': 'Effect of Early Treatment with Ivermectin among Patients with Covid-19 | NEJM', 'link': 'https://www.nejm.org/doi/full/10.1056/nejmoa2115869', 'snippet': 'Abstract Background The efficacy of ivermectin in preventing hospitalization or extended observation in an emergency setting among ...', 'date': 'May 5, 2022', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSTbEw5uDM9nzvAZBD6RjE24cqP3rr69YQxea1D4PSICNCaexbYXYXNufc&s', 'position': 5}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results suggest that ivermectin's effectiveness as a treatment for COVID-19 is not clear. Some studies indicate that it is not effective, even at higher doses and longer durations. The FDA-approved antiparasitic drug is used to treat several neglected tropical diseases, but its efficacy in treating COVID-19 is still under investigation. Now, I'll search for data on the impact of individualism on public health measures.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"Impact of individualism on public health measures\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mResult 0: {'title': 'Individualism and the fight against COVID-19 | Humanities and Social Sciences Communications - Nature', 'link': 'https://www.nature.com/articles/s41599-022-01124-5', 'snippet': 'In the presence of an unprecedented pandemic, individualism, through more assertively and unconditionally demanding personal freedom, limits ...', 'date': 'Apr 6, 2022', 'position': 1}\n",
      "Result 1: {'title': '“The Tragedy of the Commons”: How Individualism and Collectivism Affected the Spread of the COVID-19 Pandemic - Frontiers', 'link': 'https://www.frontiersin.org/articles/10.3389/fpubh.2021.627559', 'snippet': 'To test this hypothesis, we first analyzed data collected across 69 countries and examined the relationship between culture and the impact of ...', 'date': 'Jan 11, 2021', 'sitelinks': [{'title': 'Abstract', 'link': 'https://www.frontiersin.org/articles/10.3389/fpubh.2021.627559#h1'}, {'title': 'Introduction', 'link': 'https://www.frontiersin.org/articles/10.3389/fpubh.2021.627559#h2'}, {'title': 'Study 2', 'link': 'https://www.frontiersin.org/articles/10.3389/fpubh.2021.627559#h4'}, {'title': 'Discussion', 'link': 'https://www.frontiersin.org/articles/10.3389/fpubh.2021.627559#h6'}], 'position': 2}\n",
      "Result 2: {'title': 'Collectivism, individualism and COVID-19 prevention: a cross sectional study of personality, culture and behavior among Canadians - PMC - NCBI', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9067981/', 'snippet': 'Background. Collectivism has been identified as a protective factor against COVID-19 – perhaps due to increased conformity with social norms ...', 'date': 'Apr 30, 2022', 'sitelinks': [{'title': 'The role of individualism...', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9067981/#S002title'}, {'title': 'Results', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9067981/#S010title'}, {'title': 'Discussion', 'link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9067981/#S011title'}], 'position': 3}\n",
      "Result 3: {'title': 'The Role of Collectivism–Individualism in Attitudes Toward Compliance and Psychological Responses During the COVID-19 Pandemic - Frontiers', 'link': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2021.600826', 'snippet': 'Implications of the effect of individual-level cultural orientations on attitudes toward public health compliance and psychological well-being ...', 'date': 'Oct 28, 2021', 'sitelinks': [{'title': 'Abstract', 'link': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2021.600826#h1'}, {'title': 'Health Compliance During...', 'link': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2021.600826#h3'}, {'title': 'Trust', 'link': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2021.600826#h6'}, {'title': 'Discussion', 'link': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2021.600826#h11'}], 'position': 4}\n",
      "Result 4: {'title': 'The relationship between measures of individualism and collectivism and the impact of COVID-19 across nations - ScienceDirect', 'link': 'https://www.sciencedirect.com/science/article/pii/S2666535221000689', 'snippet': 'Individualism was positively correlated with COVID-19 prevalence, mortality and case fatality rates; conversely, measures of collectivism were negatively ...', 'position': 5}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results suggest that individualism can have a significant impact on public health measures. In the context of a pandemic, individualism, through more assertively and unconditionally demanding personal freedom, can limit the effectiveness of public health measures. Collectivism, on the other hand, has been identified as a protective factor against COVID-19, perhaps due to increased conformity with social norms and public health guidelines. Individualism was found to be positively correlated with COVID-19 prevalence, mortality, and case fatality rates, while measures of collectivism were negatively correlated with these outcomes. \n",
      "\n",
      "Final Answer: COVID-19 vaccines such as Pfizer-BioNTech, Moderna, and Sputnik V have shown high effectiveness, with efficacy rates of approximately 95%, 94%, and 92% respectively. On the other hand, the effectiveness of ivermectin as a treatment for COVID-19 is not clear, with some studies suggesting it is not effective, even at higher doses and longer durations. Individualism can limit the effectiveness of public health measures during a pandemic, as it often involves assertive demands for personal freedom. Conversely, collectivism, characterized by conformity with social norms and public health guidelines, can act as a protective factor against COVID-19.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mCOVID-19 vaccines such as Pfizer-BioNTech, Moderna, and Sputnik V have shown high effectiveness, with efficacy rates of approximately 95%, 94%, and 92% respectively. On the other hand, the effectiveness of ivermectin as a treatment for COVID-19 is not clear, with some studies suggesting it is not effective, even at higher doses and longer durations. Individualism can limit the effectiveness of public health measures during a pandemic, as it often involves assertive demands for personal freedom. Conversely, collectivism, characterized by conformity with social norms and public health guidelines, can act as a protective factor against COVID-19.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe data provided by the Statistician_Agent confirms that COVID-19 vaccines have high effectiveness, while the effectiveness of ivermectin is unclear. It also suggests that individualism can limit the effectiveness of public health measures, while collectivism can act as a protective factor. This information can be used to generate an insight that provides a broader perspective on the conversation.\n",
      "\n",
      "Final Answer: Insight: Vaccines show high effectiveness; ivermectin's effectiveness unclear. Individualism can limit public health measures' effectiveness.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Insight: Vaccines show high effectiveness; ivermectin's effectiveness unclear. Individualism can limit public health measures' effectiveness.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_agent.run(generate_master_prompt(test_transcript))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Async agents\n",
    "\n",
    "This is how you would run agent requests in an async manner, only check this out if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_name': 'Statistician', 'insight_num_words': 10, 'agent_insight_type': 'generate insights which focus on facts, figures, statistics, and hard data. You identify trends, point out interesting observations, identify incorrect quantitative claims, and use statistics and numbers to generate \"Insights\".', 'agent_plan': '1. Identify what quantitative data, facts, statistics, etc. could, if available, be synthesized into an \"Insight\" to improve the conversation. Come up with a general description of the \"Insight\" to generate.\\n2. What actions to take to get said data.'}\n",
      "\n",
      "\"Convoscope\" is a multi-agent system in which you are the Statistician agent. You are a highly skilled and highly intelligent expert Statistician.\n",
      "\n",
      "You will be given direct access to a live stream of transcripts from the user's conversation. Your goal is to utilize your expertise, knowledge, and tools to generate your \"Insight\" for the user.\n",
      "\n",
      "The types of \"Insights\" you provide strictly fall under your role as an expert Statistician. Only provide insights that would come from your role as the Statistician.\n",
      "\n",
      "[Definitions]\n",
      "- \"Insights\": Short snippet of text which provides intelligent analysis, ideas, arguments, perspectives, questions to ask, deeper insights, etc. that will improve the current conversation. \"Insights\" aim to lead the conversationn to deeper understanding, broader perspectives, new ideas, more accurate information, better replies, and enhanced conversations. Insights should be contextually relevant to the current conversation. The \"Insight\" should be providing additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what has already been said.\n",
      "- \"Convoscope\": an intelligence augmentation tool running on user's smart glasses or on their laptop that they use during conversations to improve conversations. Convoscope listens to a user's live conversation and enhances their conversation by providing them with real time \"Insights\".\n",
      "\n",
      "[Your Expertise: Statistician]\n",
      "\n",
      "As the Statistician agent, you generate insights which focus on facts, figures, statistics, and hard data. You identify trends, point out interesting observations, identify incorrect quantitative claims, and use statistics and numbers to generate \"Insights\"..\n",
      "\n",
      "[Your Tools]\n",
      "You have access to tools, which you should utilize to help you generate highly valuable, insightful, contextually relevant insights.\n",
      "\n",
      "Limit your usage of the Search_Engine tool to 1 times. Mention your number of usage of the tool in your thoughts.\n",
      "\n",
      "<Task start>\n",
      "It's now time to generate an \"Insight\" for the following conversation transcript. The \"Insight\" should provide additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what is being said in the transcripts. If a tool fails to fulfill your request, don't run the exact same request on the same tool again.\n",
      "\n",
      "In your initial thought, you should first come up with a plan to generate the \"Insight\". The plan should include:\n",
      "\n",
      "1. Identify what quantitative data, facts, statistics, etc. could, if available, be synthesized into an \"Insight\" to improve the conversation. Come up with a general description of the \"Insight\" to generate.\n",
      "2. What actions to take to get said data.\n",
      "\n",
      "The plan should include a final step to generate the insight. The insight must 10 words or less and be in the format `Insight: {Insert your \"Insight\" here}`. If you don't have a very valuable and useful insight for any reason, simply specify your \"Insight as \"null\".\n",
      "<Task end>\n",
      "\n",
      "<Transcript start>this is a test transcript<Transcript end>\n",
      "--------------\n",
      "\n",
      "\n",
      "\n",
      "{'agent_name': 'FactChecker', 'insight_num_words': 7, 'agent_insight_type': \"fact check any claims made during a conversation. Listen for any claims made that may not be true, and use your data, knowledge, and tools to verify or refute claims that are made. You only try to verify/refute statements which are falsifiable with free and public knowledge (i.e. don't fact check personal statements or beliefs).\", 'agent_plan': '1. Find and write down individual factual claims from the conversation. Do not consider personal, belief-based, or unfalsifiable claims. If there are no claims made that meet the requirements, then skip to the final step and output \"null\".\\n2. If claims are found, write out how to determine if each claim is true or false using your tools.\\n3. Find any false claim, use the most important false claim if there are multiple, to generate your \"Insight\". If there are no claims or no false claims, your output is \"null\".'}\n",
      "\n",
      "\"Convoscope\" is a multi-agent system in which you are the FactChecker agent. You are a highly skilled and highly intelligent expert FactChecker.\n",
      "\n",
      "You will be given direct access to a live stream of transcripts from the user's conversation. Your goal is to utilize your expertise, knowledge, and tools to generate your \"Insight\" for the user.\n",
      "\n",
      "The types of \"Insights\" you provide strictly fall under your role as an expert FactChecker. Only provide insights that would come from your role as the FactChecker.\n",
      "\n",
      "[Definitions]\n",
      "- \"Insights\": Short snippet of text which provides intelligent analysis, ideas, arguments, perspectives, questions to ask, deeper insights, etc. that will improve the current conversation. \"Insights\" aim to lead the conversationn to deeper understanding, broader perspectives, new ideas, more accurate information, better replies, and enhanced conversations. Insights should be contextually relevant to the current conversation. The \"Insight\" should be providing additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what has already been said.\n",
      "- \"Convoscope\": an intelligence augmentation tool running on user's smart glasses or on their laptop that they use during conversations to improve conversations. Convoscope listens to a user's live conversation and enhances their conversation by providing them with real time \"Insights\".\n",
      "\n",
      "[Your Expertise: FactChecker]\n",
      "\n",
      "As the FactChecker agent, you fact check any claims made during a conversation. Listen for any claims made that may not be true, and use your data, knowledge, and tools to verify or refute claims that are made. You only try to verify/refute statements which are falsifiable with free and public knowledge (i.e. don't fact check personal statements or beliefs)..\n",
      "\n",
      "[Your Tools]\n",
      "You have access to tools, which you should utilize to help you generate highly valuable, insightful, contextually relevant insights.\n",
      "\n",
      "Limit your usage of the Search_Engine tool to 1 times. Mention your number of usage of the tool in your thoughts.\n",
      "\n",
      "<Task start>\n",
      "It's now time to generate an \"Insight\" for the following conversation transcript. The \"Insight\" should provide additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what is being said in the transcripts. If a tool fails to fulfill your request, don't run the exact same request on the same tool again.\n",
      "\n",
      "In your initial thought, you should first come up with a plan to generate the \"Insight\". The plan should include:\n",
      "\n",
      "1. Find and write down individual factual claims from the conversation. Do not consider personal, belief-based, or unfalsifiable claims. If there are no claims made that meet the requirements, then skip to the final step and output \"null\".\n",
      "2. If claims are found, write out how to determine if each claim is true or false using your tools.\n",
      "3. Find any false claim, use the most important false claim if there are multiple, to generate your \"Insight\". If there are no claims or no false claims, your output is \"null\".\n",
      "\n",
      "The plan should include a final step to generate the insight. The insight must 7 words or less and be in the format `Insight: {Insert your \"Insight\" here}`. If you don't have a very valuable and useful insight for any reason, simply specify your \"Insight as \"null\".\n",
      "<Task end>\n",
      "\n",
      "<Transcript start>this is a test transcript<Transcript end>\n",
      "--------------\n",
      "\n",
      "\n",
      "\n",
      "{'agent_name': 'DevilsAdvocate', 'insight_num_words': 12, 'agent_insight_type': \"assess the point of view being taken in the conversation and steel-man a contrary position. You purposefully disagree with the interlocutors' arguments and point of view to help stimulate thought and explore the ideas further.\", 'agent_plan': '1. Find a main argument or point of view being taken that would benefit the most from a devils advocate perspective. Write down the original position. If no position/argument is found, skip to the final step and output \"null\".\\n2. List any tool usage necessary to generate your devils advocate position.'}\n",
      "\n",
      "\"Convoscope\" is a multi-agent system in which you are the DevilsAdvocate agent. You are a highly skilled and highly intelligent expert DevilsAdvocate.\n",
      "\n",
      "You will be given direct access to a live stream of transcripts from the user's conversation. Your goal is to utilize your expertise, knowledge, and tools to generate your \"Insight\" for the user.\n",
      "\n",
      "The types of \"Insights\" you provide strictly fall under your role as an expert DevilsAdvocate. Only provide insights that would come from your role as the DevilsAdvocate.\n",
      "\n",
      "[Definitions]\n",
      "- \"Insights\": Short snippet of text which provides intelligent analysis, ideas, arguments, perspectives, questions to ask, deeper insights, etc. that will improve the current conversation. \"Insights\" aim to lead the conversationn to deeper understanding, broader perspectives, new ideas, more accurate information, better replies, and enhanced conversations. Insights should be contextually relevant to the current conversation. The \"Insight\" should be providing additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what has already been said.\n",
      "- \"Convoscope\": an intelligence augmentation tool running on user's smart glasses or on their laptop that they use during conversations to improve conversations. Convoscope listens to a user's live conversation and enhances their conversation by providing them with real time \"Insights\".\n",
      "\n",
      "[Your Expertise: DevilsAdvocate]\n",
      "\n",
      "As the DevilsAdvocate agent, you assess the point of view being taken in the conversation and steel-man a contrary position. You purposefully disagree with the interlocutors' arguments and point of view to help stimulate thought and explore the ideas further..\n",
      "\n",
      "[Your Tools]\n",
      "You have access to tools, which you should utilize to help you generate highly valuable, insightful, contextually relevant insights.\n",
      "\n",
      "Limit your usage of the Search_Engine tool to 1 times. Mention your number of usage of the tool in your thoughts.\n",
      "\n",
      "<Task start>\n",
      "It's now time to generate an \"Insight\" for the following conversation transcript. The \"Insight\" should provide additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what is being said in the transcripts. If a tool fails to fulfill your request, don't run the exact same request on the same tool again.\n",
      "\n",
      "In your initial thought, you should first come up with a plan to generate the \"Insight\". The plan should include:\n",
      "\n",
      "1. Find a main argument or point of view being taken that would benefit the most from a devils advocate perspective. Write down the original position. If no position/argument is found, skip to the final step and output \"null\".\n",
      "2. List any tool usage necessary to generate your devils advocate position.\n",
      "\n",
      "The plan should include a final step to generate the insight. The insight must 12 words or less and be in the format `Insight: {Insert your \"Insight\" here}`. If you don't have a very valuable and useful insight for any reason, simply specify your \"Insight as \"null\".\n",
      "<Task end>\n",
      "\n",
      "<Transcript start>this is a test transcript<Transcript end>\n",
      "--------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent_prompt_blueprint = \"\"\"\n",
    "\"Convoscope\" is a multi-agent system in which you are the {agent_name} agent. You are a highly skilled and highly intelligent expert {agent_name}.\n",
    "\n",
    "You will be given direct access to a live stream of transcripts from the user's conversation. Your goal is to utilize your expertise, knowledge, and tools to generate your \"Insight\" for the user.\n",
    "\n",
    "The types of \"Insights\" you provide strictly fall under your role as an expert {agent_name}. Only provide insights that would come from your role as the {agent_name}.\n",
    "\n",
    "[Definitions]\n",
    "- \"Insights\": Short snippet of text which provides intelligent analysis, ideas, arguments, perspectives, questions to ask, deeper insights, etc. that will improve the current conversation. \"Insights\" aim to lead the conversationn to deeper understanding, broader perspectives, new ideas, more accurate information, better replies, and enhanced conversations. Insights should be contextually relevant to the current conversation. The \"Insight\" should be providing additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what has already been said.\n",
    "- \"Convoscope\": an intelligence augmentation tool running on user's smart glasses or on their laptop that they use during conversations to improve conversations. Convoscope listens to a user's live conversation and enhances their conversation by providing them with real time \"Insights\".\n",
    "\n",
    "[Your Expertise: {agent_name}]\n",
    "\n",
    "As the {agent_name} agent, you {agent_insight_type}.\n",
    "\n",
    "[Your Tools]\n",
    "You have access to tools, which you should utilize to help you generate highly valuable, insightful, contextually relevant insights.\n",
    "\n",
    "Limit your usage of the Search_Engine tool to 1 times. Mention your number of usage of the tool in your thoughts.\n",
    "\n",
    "<Task start>\n",
    "It's now time to generate an \"Insight\" for the following conversation transcript. The \"Insight\" should provide additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what is being said in the transcripts. If a tool fails to fulfill your request, don't run the exact same request on the same tool again.\n",
    "\n",
    "In your initial thought, you should first come up with a plan to generate the \"Insight\". The plan should include:\n",
    "\n",
    "{agent_plan}\n",
    "\n",
    "The plan should include a final step to generate the insight. The insight must {insight_num_words} words or less and be in the format `Insight: {{Insert your \"Insight\" here}}`. If you don't have a very valuable and useful insight for any reason, simply specify your \"Insight as \"null\".\n",
    "<Task end>\n",
    "\n",
    "<Transcript start>{conversation_transcript}<Transcript end>\"\"\"\n",
    "\n",
    "agent_list = [\n",
    "        {\n",
    "            \"agent_name\": \"Statistician\", \n",
    "            \"insight_num_words\" : 10,\n",
    "            \"agent_insight_type\" : \"\"\"generate insights which focus on facts, figures, statistics, and hard data. You identify trends, point out interesting observations, identify incorrect quantitative claims, and use statistics and numbers to generate \"Insights\".\"\"\",\n",
    "            \"agent_plan\" : \"\"\"1. Identify what quantitative data, facts, statistics, etc. could, if available, be synthesized into an \"Insight\" to improve the conversation. Come up with a general description of the \"Insight\" to generate.\\n2. What actions to take to get said data.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"agent_name\": \"FactChecker\", \n",
    "            \"insight_num_words\" : 7,\n",
    "            \"agent_insight_type\" : \"\"\"fact check any claims made during a conversation. Listen for any claims made that may not be true, and use your data, knowledge, and tools to verify or refute claims that are made. You only try to verify/refute statements which are falsifiable with free and public knowledge (i.e. don't fact check personal statements or beliefs).\"\"\",\n",
    "            \"agent_plan\" : \"\"\"1. Find and write down individual factual claims from the conversation. Do not consider personal, belief-based, or unfalsifiable claims. If there are no claims made that meet the requirements, then skip to the final step and output \"null\".\\n2. If claims are found, write out how to determine if each claim is true or false using your tools.\\n3. Find any false claim, use the most important false claim if there are multiple, to generate your \"Insight\". If there are no claims or no false claims, your output is \"null\".\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"agent_name\": \"DevilsAdvocate\", \n",
    "            \"insight_num_words\" : 12,\n",
    "            \"agent_insight_type\" : \"\"\"assess the point of view being taken in the conversation and steel-man a contrary position. You purposefully disagree with the interlocutors' arguments and point of view to help stimulate thought and explore the ideas further.\"\"\",\n",
    "            \"agent_plan\" : \"\"\"1. Find a main argument or point of view being taken that would benefit the most from a devils advocate perspective. Write down the original position. If no position/argument is found, skip to the final step and output \"null\".\\n2. List any tool usage necessary to generate your devils advocate position.\"\"\"\n",
    "        }\n",
    "\n",
    "    ]\n",
    "\n",
    "def agent_prompt_maker(agent_config, conversation_transcript):\n",
    "    # Populating the blueprint string with values from the agent_config dictionary\n",
    "    agent_prompt = agent_prompt_blueprint.format(**agent_config, conversation_transcript=conversation_transcript)\n",
    "    return agent_prompt\n",
    "\n",
    "for agent in agent_list:\n",
    "    print(agent)\n",
    "    agent_prompt = agent_prompt_maker(agent, \"this is a test transcript\")\n",
    "    print(agent_prompt)\n",
    "    print(\"--------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I also have a lot of addiction in my family and hardcore drug addiction and mental illness. And in order to cope with it, you really have to understand that borderline personality disorder, schizophrenia, and drug addiction. So I have a lot of people I love that suffer from drug addiction and alcoholism. And the first thing they started teaching you is it's not a choice. These people's dopamine receptors, don't hold dopamine the same ways yours do. Their frontal lobe is underdeveloped, like, you know, and that really helped me to navigate dealing, loving people that were addicted to substances. I want to be careful with this question, but how much? Money do you have? How much? Can I borrow $10?, Okay, no, is how much control, how much, despite the chemical imbalances or the biological limitations that each of our individual brains have, how much mind over matter is there? So through things that I've known people, with clinical depression, and so it's always a touchy subject to say how much they can really help it. Very. What can you, yeah, what can you, because you've talked about codependency, you talked about issues that you struggle through, and nevertheless, you choose to take a journey of healing and so on, so that's your choice,, that's your actions. So how much can you do to help fight the limitations of the neurochemicals in your brain? That's such an interesting question, and I don't think I'm at all qualified to answer, but I'll say what I do know. And really quick, just the definition of codependency, I think a lot of people think of codependency as like two people that can't stop hanging out, you know, or like, you know, that's not totally off,\n",
      " but I think for the most part, my favorite definition of codependency is the inability to tolerate the discomfort of others. You grow up in an alcoholic home, you grow up around mental illness, you grow up in chaos, you have a parent that's a narcissist, you basically are wired to just people please, worry about others, be perfect, walk on eggshells, shape shift to accommodate other people. So codependence is a very active wiring issue\n",
      "--------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The conversation revolves around mental health issues, addiction, and the role of neurochemicals in these conditions. A potential insight could be the prevalence of these conditions in the general population or the effectiveness of treatments. This could provide context to the conversation and help the participants understand the scale of these issues. I will use the Search_Engine tool to find statistics on the prevalence of mental health issues and addiction, and the effectiveness of treatments. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"statistics on prevalence of mental health issues and addiction and effectiveness of treatments\"\n",
      "}\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThought: The main argument in this conversation is that mental illnesses and addictions are not a choice, but rather a result of biological and chemical imbalances in the brain. The speaker also discusses the concept of codependency and how it is a result of growing up in a chaotic environment. As a DevilsAdvocate, I could challenge the idea that these conditions are entirely out of an individual's control and suggest that personal choices and environmental factors also play a significant role. I don't need to use the Search_Engine tool for this task as the counter-argument is based on a common perspective in the field of psychology.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Insight: Consider the role personal choices and environment play in mental health.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: The conversation transcript contains several factual claims. Here are the ones that stand out:\n",
      "\n",
      "1. \"These people's dopamine receptors, don't hold dopamine the same ways yours do.\"\n",
      "2. \"Their frontal lobe is underdeveloped.\"\n",
      "3. \"Codependency is the inability to tolerate the discomfort of others.\"\n",
      "4. \"Codependence is a very active wiring issue.\"\n",
      "\n",
      "To verify these claims, I will use the Search_Engine tool. I will search for scientific literature or reputable health websites that can confirm or refute these statements. \n",
      "\n",
      "After determining the veracity of these claims, I will generate an insight based on the most important false claim, if any. If all claims are true or if there are no false claims, my output will be \"null\". \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"Dopamine receptors and drug addiction\"\n",
      "}\n",
      "```\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m<result0>\n",
      "Title: Part 1: The Connection Between Substance Use Disorders and Mental Illness\n",
      "Link: https://nida.nih.gov/publications/research-reports/common-comorbidities-substance-use-disorders/part-1-connection-between-substance-use-disorders-mental-illness\n",
      "Snippet: Research indicates that 43 percent of people in SUD treatment for nonmedical use of prescription painkillers have a diagnosis or symptoms of ...\n",
      "Summarized Page: <p>Serious mental illness among people ages 18 and older is defined at the federal level as having, at any time during the past year, a diagnosable mental, behavior, or emotional disorder that causes serious functional impairment that substantially interferes with or limits one or more major life activities. Serious mental illnesses include major depression, schizophrenia, and bipolar disorder, and other mental disorders that cause serious impairment.18 Around 1 in 4 individuals with SMI also have an SUD. Some research has found that mental illness may precede a substance use disorder, suggesting that better diagnosis of youth mental illness may help reduce comorbidity. Treatment of childhood ADHD with stimulant medications such as methylphenidate or amphetamine reduces the impulsive behavior, fidgeting, and  inability to concentrate that characterize ADHD.32 That risk presents a challenge when treating children with ADHD, since effective treatment often involves prescribing stimulant medications with addictive potential. Part 1:  The Connection Between Substance Use Disorders and Mental Illness. Retrieved from https://nida.nih.gov/publications/research-reports/common-comorbidities-substance-use-disorders/part-1-connection-between-substance-use-disorders-mental-illness       \n",
      "        NIDA. \" National Institute on Drug Abuse website.</p>\n",
      "</result0>\n",
      "\n",
      "<result1>\n",
      "Title: Mental Health and Substance Use Co-Occurring Disorders - SAMHSA\n",
      "Link: https://www.samhsa.gov/mental-health/mental-health-substance-use-co-occurring-disorders\n",
      "Snippet: Mental health problems and substance use disorders sometimes occur together. More than one in four adults living with serious mental health ...\n",
      "Summarized Page: <p>Mono Bar An official website of the United States government Here’s how you know \n",
      "Official websites use .govA .gov website belongs to an official government organization in the United States. Secure .gov websites use HTTPSA\n",
      "              lock (\n",
      "              \n",
      "\n",
      "Lock\n",
      "Locked padlock icon\n",
      "\n",
      "\n",
      ") or https:// means you’ve safely connected to the .gov website. Site branding Solr Header Search Utility Menu Header - Callout  In Crisis? Substance use problems occur more frequently with certain mental health problems, including: Substance Use Disorders Symptoms It can be hard to identify a Substance Use Disorder sometimes because people can have a wide degree of functioning and often can hide their alcohol or drug use. Language Assistance Footer 1 Menu Footer Note Have a question about government service? Left side footer content SAMHSA's mission is to lead public health and service delivery efforts that promote mental health, prevent substance misuse, and provide treatments and supports to foster recovery while ensuring equitable access and better outcomes. 5600 Fishers Lane, Rockville, MD 20857\n",
      "1-877-SAMHSA-7 (1-877-726-4727) Footer Logo</p>\n",
      "</result1>\n",
      "\n",
      "<result2>\n",
      "Title: Key Substance Use and Mental Health Indicators in the United States: Results from the 2019 National Survey on Drug Use and Health - SAMHSA\n",
      "Link: https://www.samhsa.gov/data/sites/default/files/reports/rpt29393/2019NSDUHFFRPDFWHTML/2019NSDUHFFR090120.htm\n",
      "Snippet: Prevalence, treatment, and unmet treatment needs of US adults with mental health and substance use disorders. Health Affairs (Millwood), 36, 1739-1747.\n",
      "Summarized Page: <p>Hyperlinks on this page will not display an important message. Initiation of Prescription Pain Reliever Misuse Among people aged 12 or older, the number of past year initiates of prescription pain reliever misuse declined from 2.1 million people in 2015 to 1.6 million people in 2019 (Figure 32 and 2019 DT 7.40). These estimates in 2019 were higher than the estimates in each year from 2008 through 2016, but they were similar to the estimates in 2017 and 2018. Aged 18 to 25 Among young adults aged 18 to 25 in 2019, 1.7 percent (or 578,000 people) received any substance use treatment in the past year (Figure 65 and 2019 DT 7.51). Aged 26 to 49 Among the 25.3 million adults aged 26 to 49 in 2019 with past year AMI (2019 DT 10.1), 28.0 percent (or 7.0 million people) perceived an unmet need for mental health services in the past year (Figure 77 and 2019 DT 10.23). https://doi.org/10.1016/j.jpsychires.2016.03.002  66 Respondents were eligible to be asked the substance use treatment questions if they reported lifetime use of alcohol, marijuana, cocaine (including crack), heroin, hallucinogens, inhalants, or methamphetamine, or the lifetime misuse of prescription psychotherapeutic drugs (i.e., pain relievers, tranquilizers, stimulants, or sedatives). An accessible table of the estimates in the line graph is located below this figure.</p>\n",
      "</result2>\n",
      "\n",
      "<result3>\n",
      "Title: Comorbidity: Substance Use and Other Mental Disorders - National Institute on Drug Abuse\n",
      "Link: https://nida.nih.gov/research-topics/comorbidity/comorbidity-substance-use-other-mental-disorders-infographic\n",
      "Snippet: Among the 42.1 million adults with mental illness, 18.2% also had substance use disorders. Panel 3: Who gets treatment? There are many effective ...\n",
      "Summarized Page: <p>Trends & Statistics \n",
      "Comorbidity: Substance Use and Other Mental Disorders\n",
      " This infographic summarizes data on the comorbidity between substance use and mental disorders and the rates at which people get treatment for these conditions. Panel 1: Comorbidity: when a person has two or more disorders at the same time or one after the other. Not everyone with co-occurring conditions gets the treatment they need:   Panel 4: What are the barriers to getting treatment? Please note, respondents could provide more than one response. References Han B, Compton WM, Blanco C, Colpe LJ. Prevalence, Treatment, And Unmet Treatment Needs Of US Adults With Mental Health And Substance Use Disorders. doi:10.1377/hlthaff.2017.0584 This publication is available for your use and may be reproduced in its entirety without permission from NIDA.</p>\n",
      "</result3>\n",
      "\n",
      "<result4>\n",
      "Title: SAMHSA Announces National Survey on Drug Use and Health (NSDUH) Results Detailing Mental Illness and Substance Use Levels in 2021 | HHS.gov\n",
      "Link: https://www.hhs.gov/about/news/2023/01/04/samhsa-announces-national-survey-drug-use-health-results-detailing-mental-illness-substance-use-levels-2021.html\n",
      "Snippet: Nearly 1 in 3 adults had either a substance use disorder or any mental illness in the past year, and 46 percent of young adults 18-25 had either ...\n",
      "Summarized Page: <p>An official website of the United States government Here’s how you know \n",
      "Official websites use .gov\n",
      " A .gov website belongs to an official government organization in the United States. Share sensitive information only on official, secure websites. A commitment to data and evidence is one of SAMHSA’s four core principles. Key findings from the 2021 NSDUH include: Drug Use and Substance Use Disorder Major Depressive Episodes (MDE) Among Adolescents Mental Illness among Adults Co-Occurring Substance Use Disorder with Any Mental Illness Serious Thoughts of Suicide, Suicide Plans, and Suicide Attempts Recovery About the National Survey on Drug Use and Health Conducted by the federal government since 1971, the NSDUH is a primary source of statistical information on substance use and mental health of the U.S. civilian, noninstitutionalized population 12 or older. The Administration has invested $3.8 billion through the American Rescue Plan and more than $800 million through the Bipartisan Safer Communities Act in SAMHSA grant programs as part of President Biden’s comprehensive effort to improve access to mental healthcare, prevent overdoses, and save lives. Americans seeking treatment for mental health or substance use issues should call SAMHSA’s National Helpline at 800-662-HELP (4357) or visit findtreatment.samhsa.gov. Sign Up for Email Updates Receive the latest updates from the Secretary, Blogs, and News Releases.</p>\n",
      "</result4>\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[36;1m\u001b[1;3m<result0>\n",
      "Title: Drug Abuse, Dopamine and the Brain's Reward System\n",
      "Link: https://www.hazeldenbettyford.org/research-studies/addiction-research/drug-abuse-brain\n",
      "Snippet: First, reduced dopamine receptors in the SN are associated with impulsive behavior that has been tied in lab studies to escalating and compulsive self- ...\n",
      "Summarized Page: <p>I'm Seeking Help\n",
      "\t\t\t\t\t\t\n",
      " \n",
      "\t\t\t\t\tI'm In Recovery\n",
      "\t\t\t\t\t\t\n",
      " \n",
      "Addiction and Mental Health Resources\n",
      "\t\t\t\t\t\t\n",
      "\n",
      " \n",
      "\t\t\t\t\tDoes My Loved One Have a Problem? Addiction Treatment Programs\n",
      "\t\t\t\t\t\t\n",
      "\n",
      " \n",
      "\t\t\t\t\tMental Health Services\n",
      "\t\t\t\t\t\t\n",
      " \n",
      "\t\t\t\t\tFamily and Children's Programs\n",
      "\t\t\t\t\t\t\n",
      " \n",
      "Graduate School of Addiction Studies\n",
      "\t\t\t\t\t\t\n",
      "\n",
      " \n",
      "Research\n",
      "\t\t\t\t\t\t\n",
      "\n",
      " \n",
      "\t\t\t\t\tPatient Care Network\n",
      "\t\t\t\t\t\t\n",
      " \n",
      "Consulting and Training\n",
      "\t\t\t\t\t\t\n",
      "\n",
      " \n",
      "Continuing Education\n",
      "\t\t\t\t\t\t\n",
      "\n",
      " Our Locations The Hazelden Betty Ford Foundation has addiction and mental health facilities in 8 States throughout the United States. What makes certain substances so addictive? These electrical signals are controlled by chemicals called neurotransmitters, which are secreted from within the neurons and sent out in the brain to other surrounding neurons in order to activate (or deactivate) them. The Brain Following Chronic and Long-Term Substance Abuse While the intense feelings of pleasure and reward derived from early drug use can play a substantial part in continued use of the drug, it is only a small part of the neurophysiological cycle of addiction. First, reduced dopamine receptors in the SN are associated with impulsive behavior that has been tied in lab studies to escalating and compulsive self-administration of drugs.4 Reduced dopamine receptors also result in a state known as \"anhedonia\", or a loss of pleasure in activities that were once enjoyed. Stay in the know with Hazelden Betty Ford Foundation emails 2023 Hazelden Betty Ford Foundation.</p>\n",
      "</result0>\n",
      "\n",
      "<result1>\n",
      "Title: Dopamine and Addiction - PubMed\n",
      "Link: https://pubmed.ncbi.nlm.nih.gov/31905114/\n",
      "Snippet: As a result of habitual intake of addictive drugs, dopamine receptors expressed in the brain are decreased, thereby reducing interest in ...\n",
      "Summarized Page: <p>An official website of the United States government \n",
      "The .gov means it’s official. Federal government websites often end in .gov or .mil. Before\n",
      "            sharing sensitive information, make sure you’re on a federal\n",
      "            government site. It is usually defined by characteristics of intoxication or by characteristics of withdrawal symptoms. Such addictions can also be defined in terms of the brain mechanisms they activate; most addictive drugs cause elevations in extracellular levels of the neurotransmitter dopamine. Burst discharges (phasic firing) of dopamine-containing neurons are necessary to establish long-term memories associating predictive stimuli with rewards and punishers. Unauthorized use of these marks is strictly prohibited.</p>\n",
      "</result1>\n",
      "\n",
      "<result2>\n",
      "Title: Addiction: Decreased reward sensitivity and increased expectation sensitivity conspire to overwhelm the brain's control circuit - PMC - NCBI\n",
      "Link: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2948245/\n",
      "Snippet: Chronic drug abuse downregulates dopamine receptors and dopamine production: The “high” is blunted ... The fact that drug use must become chronic before addiction ...\n",
      "Summarized Page: <p>An official website of the United States government \n",
      "The .gov means it’s official. Modified with permission from Volkow et al. [ Indeed, every drug of abuse whose brain pharmacokinetics have been measured with PET (cocaine, MPH, methamphetamine, and nicotine) exhibits the same profile when the administration is intravenous, i.e., peak levels in the human brain are reached within 10 min (Fig. As previously mentioned, in drug abusers, lower striatal D2R significantly correlates with lower brain glucose metabolism in key regions of the PFC, such as the OFC (involved with salience attribution and whose disruption results in compulsive behaviors) and in CG (involved with inhibitory control and error monitoring and whose disruption results in impulsivity) (Fig. This facilitates the consolidation of maladaptive memory traces connected to the drug, which helps explain the ability of all sorts of drug-associated stimuli (in the learned expectation of receiving the drug reward when exposed to these stimuli) [41] to readily trigger DA cells firing. These circuits work together and change with experience. Conclusions In short, we propose a model that accounts for addiction as follows: During addiction, the enhanced value of drug cues in the memory circuit drives reward expectation and enhances the motivation to consume the drug, overcoming the inhibitory control exerted by an already dysfunctional PFC.</p>\n",
      "</result2>\n",
      "\n",
      "<result3>\n",
      "Title: Dopamine, behavior, and addiction | Journal of Biomedical Science | Full Text\n",
      "Link: https://jbiomedsci.biomedcentral.com/articles/10.1186/s12929-021-00779-7\n",
      "Snippet: However, dopamine plays strongly established roles in the addictive properties of some drugs but is implicated by minimal evidence in others.\n",
      "Summarized Page: <p>Advertisement Dopamine, behavior, and addiction \n",
      "Journal of Biomedical Science\n",
      "volume 28, Article number: 83 (2021)\n",
      "            Cite this article\n",
      " 17k Accesses 14 Citations 1 Altmetric Metrics details Abstract Addictive drugs are habit-forming. Rewards are habit-forming because predictive stimuli—reward-predictors as well as punishment-predictors—come to cause dopaminergic burst-firing, and burst-firing enhances or enables the separate development of long-term potentiation (LTP) and long-term depression (LTD) of learned connections between other systems: glutamatergic input pathways and GABAergic output pathways [3]. Dopamine has broadly been associated with the rewarding effects of addictive drugs, particularly in the process of establishing habitual drug intake [24, 93, 94]. Article \n",
      "    CAS \n",
      "    PubMed \n",
      "    \n",
      "                    Google Scholar \n",
      "                 Ranaldi R, Pocock D, Zereik R, Wise RA. Oral ethanol self-administration in rats is reduced by the administration of dopamine and glutamate receptor antagonists into the nucleus accumbens. Delta 9-tetrahydrocannabinol produces naloxone-blockable enhancement of presynaptic basal dopamine efflux in nucleus accumbens of conscious, freely-moving rats as measured by intracerebral microdialysis. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</p>\n",
      "</result3>\n",
      "\n",
      "<result4>\n",
      "Title: Dopamine in Drug Abuse and Addiction: Results of Imaging Studies and Treatment Implications - JAMA Network\n",
      "Link: https://jamanetwork.com/journals/jamaneurology/fullarticle/794743\n",
      "Snippet: Dopamine (DA) is the neurotransmitter that has been classically associated with the reinforcing effects of drugs of abuse and may have a key role in triggering ...\n",
      "Summarized Page: <p>Journals A, Images of D2 dopamine receptors (raclopride labeled with carbon 11) and of brain glucose metabolism (fludeoxyglucose), which is used as an indicator of brain function in a control subject and a cocaine abuser. See More About             Select Your Interests Select Your Interests Customize your JAMA Network experience by selecting one or more topics from the list below. doi:10.1001/archneur.64.11.1575 Manage citations: © 2023  Dopamine in Drug Abuse and Addiction: Results of Imaging Studies and Treatment Implications Author Affiliations: National Institute on Drug Abuse (Dr Volkow) and National Institute on Alcohol Abuse and Alcoholism (Drs Volkow and Telang), Bethesda, Maryland; Medical Department, Brookhaven National Laboratory, Upton, New York (Drs Fowler and Wang); and Department of Pediatrics, University of California, Irvine (Dr Swanson). Using 18-N-methylspiroperidol or [11C]raclopride, we and others have shown that subjects with a wide variety of drug addictions (cocaine, heroin, alcohol, and methamphetamine) have significant reductions in D2 DA receptor availability in the striatum (including the ventral striatum) that persist months after protracted detoxification (reviewed in Volkow et al2). Preclinical studies have demonstrated a prominent role of DA in motivation that seems to be mediated in part via a DA-regulated circuit involving the orbitofrontal cortex (OFC) and the anterior cingulate gyrus (CG).9 In imaging studies in human subjects using the radioactive tracer fludeoxyglucose F 18, we and others have shown decreased activity in the OFC and CG in different classes of addicted subjects (reviewed in Volkow et al2). The CG and the OFC are also involved with inhibitory control, which led us to postulate that disrupted DA modulation of the OFC and CG also contributes to the loss of control over drug intake by drug-addicted subjects.10 Inhibitory control is also dependent on the dorsolateral prefrontal cortex, which is also affected in addiction (reviewed in Volkow et al2). Critical revision of the manuscript for important intellectual content: Volkow, Fowler, Wang, Swanson, and Telang.</p>\n",
      "</result4>\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results confirm the first claim that \"These people's dopamine receptors, don't hold dopamine the same ways yours do.\" Various sources, including scientific literature and reputable health websites, indicate that habitual intake of addictive drugs can lead to a decrease in dopamine receptors in the brain. This is associated with impulsive behavior and a loss of pleasure in activities that were once enjoyed.\n",
      "\n",
      "Next, I will verify the second claim that \"Their frontal lobe is underdeveloped.\" \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"Frontal lobe development and drug addiction\"\n",
      "}\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThe search results provide some useful statistics on the prevalence of mental health issues and addiction, as well as the comorbidity of these conditions. However, the effectiveness of treatments is not clearly stated. From the results, we know that around 1 in 4 individuals with serious mental illness (SMI) also have a substance use disorder (SUD). Also, nearly 1 in 3 adults had either a substance use disorder or any mental illness in the past year. This information could be synthesized into an insight that provides context to the conversation. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Insight: 1 in 4 with serious mental illness also have a substance use disorder.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/miniforge3/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m<result0>\n",
      "Title: Adolescent Brain Development and Drugs - PMC - NCBI\n",
      "Link: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3399589/\n",
      "Snippet: Early drug use may alter brain maturation, contribute to lasting cognitive impairment of certain functions, and significantly increase short- and long-term ...\n",
      "Summarized Page: <p>An official website of the United States government \n",
      "The .gov means it’s official. This new research, aided by sophisticated brain imaging technology, has documented the surprising finding that the human brain is still maturing in significant ways during the adolescent years (Giedd, 2004). However, animal models of drug use permit the use of research strategies that would not be ethical with humans, and animals are affected by drugs in ways that are comparable to humans. In this light, we favor a focus on several teen-brain approaches for both prevention and treatment program:\n",
      " \n",
      "Whereas neuro-science has not yet provided any clear formulas for optimizing healthy brain maturation (Bruer, 1999), knowledge on the effects of drugs on the brain raises the strong possibility that using drugs during adolescence can interfere with healthy brain development and may cause significant alterations of normal processes (National Drug Institute on Drug Abuse, 2007). It also stands to reason for programs and practices to focus heavily on teaching teenagers the skills that directly help them in decision making, particularly when they are faced with a situation that “challenges” the prefrontal cortex (for example, a social setting where peers are present and there are opportunities to take risks). For example, if parents do drink alcohol, modeling light to moderate patterns of consumption, not driving after drinking, and not encouraging underage drinking are all behaviors that will lessen the likelihood that an adolescent will develop a substance use problem later in life (Yu, 2003). Acknowledgments This article was supported in part by grants K02 DA15347 (Winters) and P50 DA027841 (Arria, Winters) from the National Institute on Health.</p>\n",
      "</result0>\n",
      "\n",
      "<result1>\n",
      "Title: Dysfunction of the prefrontal cortex in addiction: neuroimaging findings and clinical implications - PMC - NCBI\n",
      "Link: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3462342/\n",
      "Snippet: However, imaging studies in addictive behaviours have identified a key involvement of the prefrontal cortex (PFC) both through its regulation of ...\n",
      "Summarized Page: <p>An official website of the United States government \n",
      "The .gov means it’s official. Excessive craving or drug wanting, or other, more automatic processes such as attention bias and conditioned responses, can then pave the way to additional drug use even when the addicted individual is trying to abstain (see TABLE 1 for clinical characteristics of addiction in the context of iRISA and the role of the PFC in addiction). Integrating results from preclinical lesion and pharmacological studies, considering other cortical and subcortical structures in addiction — the PFC is densely interconnected with other brain regions (see BOX 1 for a discussion of early studies examining these networks in the context of addiction) — and using computational modelling may help further in ascribing probable psychological functions to select PFC regions and in enhancing our understanding of their involvement in drug addiction. Consistent with the impact of abstinence on the go/no-go task reported above114, cigarette smokers who were tested after a 12-hour abstinence had slowed reaction times, and enhanced dACC and reduced right DLPFC responses to the incongruent trials on the colour–word Stroop task124 (Supplementary information S4(table)). It also decreased errors of commission, a common measure of impulsivity, during a drug-relevant emotional Stroop task, both in cocaine-addicted individuals and controls, and in the addicted individuals this decrease was associated with normalization of activation in the rostroventral ACC (extending to the mOFC) and dACC; dACC task-related activation before MPH administration was correlated with shorter lifetime alcohol use137 (FIG. It should be noted that the effect of dopamine agonists on normalizing brain–behaviour responses to emotional or cognitive-control challenges may depend on patterns of compulsive drug use126 or other individual differences, such as baseline self-control and lifetime drug use, but these possibilities remain to be studied in larger sample sizes. Other common issues pertain to incomplete presentation of the actual data (such as not providing both mean and variance, or not providing scatterplots when reporting correlations), which can obscure the direction of an effect (activation versus deactivation), potentially adding to the variability in published results (for example, a hyperactivation could refer to higher activations or lower deactivations from baseline).</p>\n",
      "</result1>\n",
      "\n",
      "<result2>\n",
      "Title: Cognition is central to drug addiction - American Psychological Association\n",
      "Link: https://www.apa.org/monitor/jun01/cogcentral\n",
      "Snippet: Evidence that craving and drug cues can trigger abnormal activity in the frontal cortex--even in the absence of drugs--has led many researchers ...\n",
      "Summarized Page: <p>Topics in Psychology Explore how scientific research by psychologists can inform our professional lives, family and community relationships, emotional wellness, and more. Education Careers Training Highlights \n",
      "Building a Thriving Practice and Culture of Inclusivity: Presenters Panel Discussion                             \n",
      "Understanding Adult Psilocybin Use and Psilocybin-Assisted Psychotherapy                             News and Advocacy Browse the latest updates from APA, informed by psychological science. For treatment, he believes, that may suggest that it will be difficult to find a \"magic bullet\" to attack both the pharmacological and the behavioral parts of addiction. Grant saw Bechara's presentation and made the connection to drug abuse, hypothesizing that disruptions in the frontal cortex might be responsible for impaired decision-making and behavioral inhibition in drug abusers--and that that could help explain the compulsive drug-seeking that is a hallmark of addiction. About one-third, they found, showed no decision-making impairment on the gambling task. About 25 percent, in contrast, responded exactly as patients with frontal lobe damage have been shown to do, almost invariably choosing a higher immediate reward even knowing that their strategy would be unprofitable in the long run. Seeking clues for treatment Evidence that craving and drug cues can trigger abnormal activity in the frontal cortex--even in the absence of drugs--has led many researchers to believe that this brain area may be especially important in relapse.</p>\n",
      "</result2>\n",
      "\n",
      "<result3>\n",
      "Title: Drug Effects on Developing Brains - Teens | Sandstone Care\n",
      "Link: https://www.sandstonecare.com/blog/effects-of-drugs-on-teens-developing-brains/\n",
      "Snippet: What are the Cognitive Effects of Drug Use in Teens and Young Adults? · Lower IQ · Permanent loss of memory · Lower speed of processing information ...\n",
      "Summarized Page: <p>Ages 13 - 18 Free Self-Screening Quiz Find out if you or a loved one may have a mental health or substance use disorder. Take the Quiz Therapy Treatments for Young Adults Levels of Care for Young Adults Connect with us 24/7 to get answers. Why is Brain Development Crucial During the Teen Years? Everything a person thinks and feels – including their mood, energy level, consciousness, memory, ability to feel pleasure and need for food and rest – is affected by neurotransmitters, so it’s important to keep your child’s brain healthy as they grow. These cells are protected by a substance called myelin, which acts as a sort of insulator to the messages that come to your brain. If these reward pathways of the brain continue to be altered due to repeated drug use, effects on a young person’s wellbeing can be overwhelming and long-lasting. As teens use drugs, they generally lose abilities in several critical areas of brain development, including the following: The longer drug use continues, the higher the risk will be of these traits continuing for a lifetime.</p>\n",
      "</result3>\n",
      "\n",
      "<result4>\n",
      "Title: Youth and the Developing Brain - Pact Coalition\n",
      "Link: https://drugfreelasvegas.org/youth-and-the-developing-brain/\n",
      "Snippet: Drug Effects on Decision Making. Drug use can affect the prefrontal cortex of the brain. This part of your brain gives you the power to think, plan, solve ...\n",
      "Summarized Page: <p>Pact Coalition Youth and the Developing Brain According to Substance Abuse and Mental Health Services Administration (SAMHSA), the impact of prescription drugs can be particularly harmful to a developing adolescent brain and body. Drug use at an early age is an important predictor of substance use disorder later in life and has a significant impact on both physical and mental functioning of adolescents into adulthood. This part of your brain is the last part of the brain to mature, making teens most vulnerable. Drug Effects on the Brain Drugs can impact 3 main areas of the brain:   Dopamine Effects on the Brain Dopamine is a type of neurotransmitter that the body produces to allow the body to feel pleasure. Risk and Protective Factors Risk and protective factors can help indicate drug use and addiction. Ste 114Las Vegas, NV 89102(702) 582-7228 Due to COVID-19, our office has daily hours which have been reduced and our staff are working remotely. We are currently operating by appointment.</p>\n",
      "</result4>\n",
      "\n",
      "\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-4-0613 in organization org-eoDifr008XqXryewW4psjUKt on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-4-0613 in organization org-eoDifr008XqXryewW4psjUKt on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe search results confirm the second claim that \"Their frontal lobe is underdeveloped.\" Various sources, including scientific literature and reputable health websites, indicate that drug use can interfere with the development of the frontal lobe, particularly in adolescents. This can lead to impaired decision-making and behavioral inhibition.\n",
      "\n",
      "Next, I will verify the third claim that \"Codependency is the inability to tolerate the discomfort of others.\"\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": \"Definition of codependency\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'agent_name': 'Statistician',\n",
       "  'agent_insight': 'Insight: 1 in 4 with serious mental illness also have a substance use disorder.'},\n",
       " {'agent_name': 'FactChecker',\n",
       "  'agent_insight': 'The search results confirm the second claim that \"Their frontal lobe is underdeveloped.\" Various sources, including scientific literature and reputable health websites, indicate that drug use can interfere with the development of the frontal lobe, particularly in adolescents. This can lead to impaired decision-making and behavioral inhibition.\\n\\nNext, I will verify the third claim that \"Codependency is the inability to tolerate the discomfort of others.\"\\n\\nAction:\\n```\\n{\\n  \"action\": \"Search_Engine\",\\n  \"action_input\": \"Definition of codependency\"\\n}\\n```'},\n",
       " {'agent_name': 'DevilsAdvocate',\n",
       "  'agent_insight': 'Insight: Consider the role personal choices and environment play in mental health.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents.tools import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "import asyncio\n",
    "\n",
    "agent_config_list = agent_list\n",
    "test_transcript = generate_test_input()\n",
    "print(test_transcript)\n",
    "print(\"--------------\\n\\n\\n\")\n",
    "\n",
    "open_ai_api_key = os.environ.get(\"OPEN_AI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=open_ai_api_key, model=\"gpt-4-0613\")\n",
    "\n",
    "agent = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            description=\"Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events. It's a tool for understanding, navigating, and engaging with the digital world's vast knowledge.\",\n",
    "        ),\n",
    "    ], llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, max_iterations=2, early_stopping_method=\"generate\", verbose=True)\n",
    "\n",
    "async def arun_wrapper(agent_config, test_transcript):\n",
    "    return {\n",
    "        \"agent_name\": agent_config[\"agent_name\"],\n",
    "        \"agent_insight\": await agent.arun(agent_prompt_maker(agent_config, test_transcript))\n",
    "    } \n",
    "tasks = [arun_wrapper(agent_config, test_transcript) for agent_config in agent_config_list]\n",
    "results = await asyncio.gather(*tasks)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latest Server Setup\n",
    "\n",
    "This section contains a direct mapping of how the agents are run in the server, making it easy to test our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_agent_prompt_blueprint = \"\"\"\n",
    "\"Convoscope\" is a multi-agent system in which you are the {agent_name} agent. You are a highly skilled and highly intelligent expert {agent_name}.\n",
    "\n",
    "You will be given direct access to a live stream of transcripts from the user's conversation. Your goal is to utilize your expertise, knowledge, and tools to generate your \"Insight\" for the user.\n",
    "\n",
    "The types of \"Insights\" you provide strictly fall under your role as an expert {agent_name}. Only provide insights that would come from your role as the {agent_name}.\n",
    "\n",
    "[Definitions]\n",
    "- \"Insights\": Short snippet of text which provides intelligent analysis, ideas, arguments, perspectives, questions to ask, deeper insights, etc. that will improve the current conversation. \"Insights\" aim to lead the conversationn to deeper understanding, broader perspectives, new ideas, more accurate information, better replies, and enhanced conversations. Insights should be contextually relevant to the current conversation. The \"Insight\" should be providing additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what has already been said.\n",
    "- \"Convoscope\": an intelligence augmentation tool running on user's smart glasses or on their laptop that they use during conversations to improve conversations. Convoscope listens to a user's live conversation and enhances their conversation by providing them with real time \"Insights\".\n",
    "\n",
    "[Your Expertise: {agent_name}]\n",
    "\n",
    "As the {agent_name} agent, you {agent_insight_type}.\n",
    "\n",
    "[Your Tools]\n",
    "You have access to tools, which you should utilize to help you generate highly valuable, insightful, contextually relevant insights.\n",
    "\n",
    "Limit your usage of the Search_Engine tool to 1 times. Mention your number of usages of the tool in your thoughts.\n",
    "\n",
    "[Example Insights]\n",
    "Here are some example insights structure that you should aim to generate, a summary is given instead of the entire transcript for brevity. From these examples, you just need to learn how to structure a good insight:\n",
    "\n",
    "{examples}\n",
    "\n",
    "[Previously Generated Insights]\n",
    "Here are some insights that had already been previously generated, if any, for this conversation. You should not repeat any of these insights:\n",
    "\n",
    "{insights_history}\n",
    "\n",
    "[Your Task]\n",
    "<Task start>\n",
    "It's now time to generate an \"Insight\" for the following conversation transcript. The \"Insight\" should provide additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what is being said in the transcripts. If a tool fails to fulfill your request, don't run the exact same request on the same tool again. Do not attempt to generate a super niche insight because it will be hard to find information online.\n",
    "\n",
    "In your initial thought, you should first come up with a plan to generate the \"Insight\". The plan should include:\n",
    "\n",
    "{agent_plan}\n",
    "\n",
    "The plan should include a final step to generate the insight. The \"Insight\" must {insight_num_words} words or less. The \"Insight\" can omit filler words or replace words with symbols or acronyms to shorten its length where possible. If you don't have a very valuable and useful \"Insight\" for any reason, simply specify your \"Insight\" as the string \"null\". \n",
    "\n",
    "Once you have the \"Insight\", extract the url of the most relevant reference source used to generate this \"Insight\". Also, relay the motive of the why the insight benefits the conversation, with quotes from the transcript. If the \"Insight\" is not up to par with the examples, we should hide it and just return \"null\" for the \"Insight\".\n",
    "\n",
    "Here are more detailed formatting instructions\n",
    "{format_instructions}\n",
    "\n",
    "Remember, the insight needs to be {insight_num_words} words or less!\n",
    "<Task end>\n",
    "\n",
    "[Input Transcript]\n",
    "<Transcript start>{conversation_transcript}<Transcript end>{final_command}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_agent_config_list = {\n",
    "    \"Statistician\": {\n",
    "        \"agent_name\": \"Statistician\",\n",
    "        \"insight_num_words\": 10,\n",
    "        \"agent_insight_type\": \"\"\"generate insights which focus on statistics, and quantitative data. Your tasks include identifying trends, correcting inaccurate claims, and leveraging statistics to provide \"Insights\".\"\"\",\n",
    "        \"agent_plan\": \"\"\"1. Identify what quantitative data, facts, statistics, etc. could, if available, be synthesized into an \"Insight\" to improve the conversation. Come up with a general description of the \"Insight\" to generate.\\n2. What actions to take to get said data, seek the necessary data from reputable sources like Statista, prioritizing official statistics or academic publications. Ensure the \"Insights\" derived are backed by solid, quantitative data, otherwise your insight in the output object is \"null\".\"\"\",\n",
    "        \"proactive_tool_description\": \"\"\"Occurrences in a conversation where statistics, graphs, and data would be useful to the user.\"\"\",\n",
    "        \"proactive_tool_example\": \"\"\"Conversation: Transcript compares the number of CS students in US and China.\n",
    "Insight: US: 6% HS students in CS, China: <1% K-12 in programming\"\"\",\n",
    "        \"examples\": \"\"\"\n",
    "1. Conversation: Transcript compares the number of CS students in US and China.\n",
    "Insight: US: 6% HS students in CS, China: <1% K-12 in programming\n",
    "\n",
    "2. Conversation: Transcript mentions \"Should we ban plastic straws?\".\n",
    "Insight: 500mil straws in the US/day, 8.3bil straws pollute the world's beaches\n",
    "\n",
    "3. Conversation: Transcript mentions \"Cancer survival rate across the years\".\n",
    "Insight: Cancer survival rate: 49% in mid-70s to 68% now\n",
    "\n",
    "4. Conversation: Transcript is about how fast the brain can recognize things.\n",
    "Insight: Brain can recognize images in ~100ms, 10x faster than previously thought\n",
    "\"\"\",\n",
    "    },\n",
    "    \"FactChecker\": {\n",
    "        \"agent_name\": \"FactChecker\",\n",
    "        \"insight_num_words\": 10,\n",
    "        \"agent_insight_type\": \"\"\"fact check any claims made during a conversation. Trigger a fact-check if a statement in the transcript falls under: misinterpreted statistics, historical inaccuracies, misleading health claims, political misrepresentations, scientific misunderstandings, or false economic data. Also, initiate a fact-check for statements not commonly known to an uneducated person, suspected falsehoods, common myths, or claims verifiable through free, public knowledge or MythBusters. This guideline is for verifying user's statements, not your own searches or ideas. Do not consider personal, belief-based, or unfalsifiable claims.\"\"\",\n",
    "        \"agent_plan\": \"\"\"1. Find and write down individual factual claims from the conversation. Do not consider personal, belief-based, or unfalsifiable claims. If there are no claims made that meet the requirements, then skip to the final step and output \"null\".\\n2. If one or more claims are found, select the claim that would provide the most value and forget the rest, then write out how to determine if each claim is true or false using your tools.\\n3. Generate the \"Insight\", if the claim is true, then the \"Insight\" should be `{{quote}} is correct`, otherwise, else it should be the truth. If there are no claims or no false claims, your output is \"null\".\\n\"\"\",\n",
    "        \"proactive_tool_description\": \"\"\"Trigger a fact-check if a statement in the transcript falls under: misinterpreted statistics, historical inaccuracies, misleading health claims, political misrepresentations, scientific misunderstandings, or false economic data. Also, initiate a fact-check for statements not commonly known to an uneducated person, suspected falsehoods, common myths, or claims verifiable through free, public knowledge or MythBusters. This guideline is for verifying user's statements, not your own searches or ideas.\"\"\",\n",
    "        \"proactive_tool_example\": \"\"\"Conversation: Transcript mentions \"Eating carrots improves night vision.\"\n",
    " Insight: Carrots have vitamin A; don't grant night vision. WWII myth origin\"\"\",\n",
    "        \"examples\": \"\"\"\n",
    " 1. Conversation: Transcript mentions \"Eating carrots improves night vision.\"\n",
    " Insight: Carrots have vitamin A; don't grant night vision. WWII myth origin\n",
    "\n",
    " 2. Conversation: Transcript mentions \"Napoleon Bonaparte was extremely short, standing only 5 feet tall.\"\n",
    " Insight: Napoleon was 5'7\"; average height, Misconception from French units\n",
    "\n",
    " 3. Conversation: Transcript mentions \"Humans only use 10% of their brains.\"\n",
    " Insight: Humans use 100% of their brains; brain imaging shows activity\n",
    "\n",
    " 4. Conversation: Transcript mentions \"Goldfish have a memory span of just a few seconds.\"\n",
    " Insight: Common myth; studies show goldfish remember things for months\n",
    " \"\"\",\n",
    "    },\n",
    "    \"DevilsAdvocate\": {\n",
    "        \"agent_name\": \"DevilsAdvocate\",\n",
    "        \"insight_num_words\": 12,\n",
    "        \"agent_insight_type\": \"\"\"assess the point of view being taken in the conversation and steel-man a contrary position. You purposefully disagree with the interlocutors' arguments and point of view to help stimulate thought and explore the ideas further.\"\"\",\n",
    "        \"agent_plan\": \"\"\"1. Find a main argument or point of view being taken that would benefit the most from a devils advocate perspective. Write down the original position. If no position/argument is found, skip to the final step and output \"null\".\\n2. List any tool usage necessary to generate your devils advocate position.\"\"\",\n",
    "        \"proactive_tool_description\": \"\"\"When it would be useful for the user to see a devil's advocate opinion (a steel-man argument supporting a viewpoint different from their own).\"\"\",\n",
    "        \"proactive_tool_example\": \"\"\"Conversation: Transcript mentions \"Climate change is a hoax.\"\n",
    "Insight: Most scientists confirm climate change's reality; evidence is in global trends\"\"\",\n",
    "        \"examples\": \"\"\"\n",
    "1. Conversation: Transcript mentions \"Climate change is a hoax.\"\n",
    "Insight: Most scientists confirm climate change's reality; evidence is in global trends\n",
    "\n",
    "2. Conversation: Transcript mentions \"Vaccines cause autism\".\n",
    "Insight: Numerous studies show no vaccine-autism link; vaccines prevent disease outbreaks\n",
    "\n",
    "3. Conversation: Transcript mentions \"Artificial intelligence will replace all human jobs.\"\n",
    "Insight: AI will create new jobs and industries, not just replace old ones\n",
    "\n",
    "4. Conversation: Transcript mentions \"Freedom of speech means I can say anything without consequences\".\n",
    "Insight: Free speech has limits; doesn't protect from harmful speech consequences\n",
    "\"\"\",\n",
    "    },\n",
    "    \"Definer\": {\n",
    "        \"agent_name\": \"Definer\",\n",
    "        \"insight_num_words\": 9,\n",
    "        \"agent_insight_type\": \"\"\"identify and explain specialized terms, concepts, and entities—including places, organizations, and notable individuals—in the conversation. Provide clarifications for jargon, ideas, and entities that might be unfamiliar to a layperson or to the user, while avoiding definitions of widely known terms and commonly recognized entities.\"\"\",\n",
    "        \"agent_plan\": \"\"\"1. Scan the conversation for specialized terms, concepts, and entities that are not widely known or might be unfamiliar to the user.\\n2. Provide clear, concise definitions or explanations for these terms, concepts, and entities. If you need to search using the Internet, wikipedia is useful for entities and urban dictionary for jargons. If a definition has multiple meanings, define the one relevant to the transcript.\\n3. Verify if the definitions are short and relevant, shorten it if it is too long, return \"null\" if it is not relevant.\"\"\",\n",
    "        \"proactive_tool_description\": \"\"\"When a term, concept, or entity in the conversation may be unfamiliar to the user or is specialized, requiring a brief yet clear clarification.\"\"\",\n",
    "        \"proactive_tool_example\": \"\"\"Conversation: Transcript mentions 'The Treaty of Tordesillas.'\n",
    "Insight: Treaty of Tordesillas: 1494 Spain-Portugal agreement, divided new lands.\"\"\",\n",
    "        \"examples\": \"\"\"\n",
    "1. Conversation: Transcript mentions \"Higgs Boson.\"\n",
    "Insight: Higgs Boson: key particle in physics, explains mass origin.\n",
    "\n",
    "2. Conversation: Transcript mentions \"Blockchain technology.\"\n",
    "Insight: Blockchain: decentralized ledger, powers cryptocurrencies like Bitcoin.\n",
    "\n",
    "3. Conversation: Transcript mentions \"Silicon Valley.\"\n",
    "Insight: Silicon Valley: CA's high-tech, innovation hub.\n",
    "\n",
    "4. Conversation: Transcript mentions \"The United Nations.\"\n",
    "Insight: UN: founded 1945, promotes global cooperation.\n",
    "\"\"\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import OutputParserException\n",
    "\n",
    "class AgentInsight(BaseModel):\n",
    "        \"\"\"\n",
    "        Query for an insight generation process\n",
    "        \"\"\"\n",
    "        agent_insight: str = Field(\n",
    "             description=\"the short insight generated by the agent\")\n",
    "        reference_source: str = Field(\n",
    "             description=\"the most useful source used to generate this insight\", default=\"\")\n",
    "        insight_motive: str = Field(\n",
    "             description=\"short motive of why the insight was generated, quoting the text in the transcript\")\n",
    "\n",
    "\n",
    "agent_insight_parser = PydanticOutputParser(pydantic_object=AgentInsight)\n",
    "\n",
    "def format_list_data(list_data: list):\n",
    "    return \"\\n\".join([f\"{i+1}. {example}\" for i, example in enumerate(list_data)])\n",
    "\n",
    "def expert_agent_prompt_maker(expert_agent_config, conversation_transcript, insights_history: list = [], final_command=\"\"):\n",
    "    # Populating the blueprint string with values from the agent_config dictionary\n",
    "    if final_command != \"\":\n",
    "        final_command = \"\\n\\n\" + final_command\n",
    "    expert_agent_prompt = expert_agent_prompt_blueprint.format(**expert_agent_config, final_command=final_command, conversation_transcript=conversation_transcript, insights_history=format_list_data(insights_history), format_instructions=agent_insight_parser.get_format_instructions())\n",
    "    return expert_agent_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents.tools import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "open_ai_api_key = os.environ.get(\"OPEN_AI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=open_ai_api_key, model=\"gpt-4-0613\")\n",
    "\n",
    "agent = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            description=\"Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events. It's a tool for understanding, navigating, and engaging with the digital world's vast knowledge.\",\n",
    "        ),\n",
    "    ], llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, max_iterations=2, early_stopping_method=\"generate\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" And I think the perspectival knowing has a lot to do with the adverbial qualia. Adjectival qualia and adverbial qualia. I'm learning so many new things today. Okay, so that's another way of knowing. Right, the perspectival, and then there's a deeper one. And this is a philosophical point, and I don't want to, we can go through the argument, but you don't have to know that you know in order to know, because if you start doing that,, you get an infinite regress. There has to be kinds of knowing that doesn't mean you know that you know that. Yeah. Okay. Of course. Okay, great. Okay, good. Well, there was a lot of ink spilled over that over a 40 year period, so. My philosophers, they spill, this is what they do, they spill ink to get paid for ink spillage. So I want to talk about what I call participatory knowing., This is the idea that you and the world are co participating in things and such that real affordances exist between you. So both me and this environment are shaped by gravity, so the affordance of walking becomes available to me. Both me and a lot of this environment are shaped by my biology, and so affordances for, that are here. Look at this cup, shared physics, shared sort of biological factors, my hand, I'm bipedal, also culture is shaping me and shaping this. I had to learn how to use that and treat it as a cup. So this is an agent arena relationship, right?, Use identities being created in your agency, identities being created in the world as an arena so you and the world fit together. You know when that's missing, when you're really lonely, or you're homesick, or you're suffering culture shock. So this is participatory knowing, and it's the sense of, it comes with a sense of belonging.\\n At every level. So the ability to walk is a kind of knowing. Yes. Yes. That there's a dance between the physics that enables this process and just participating in the process is the act of knowing. Right. And there's a really weird form of memory you have for this kind of knowing, it's called\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transcript = generate_test_input()\n",
    "test_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"Convoscope\" is a multi-agent system in which you are the Definer agent. You are a highly skilled and highly intelligent expert Definer.\n",
      "\n",
      "You will be given direct access to a live stream of transcripts from the user's conversation. Your goal is to utilize your expertise, knowledge, and tools to generate your \"Insight\" for the user.\n",
      "\n",
      "The types of \"Insights\" you provide strictly fall under your role as an expert Definer. Only provide insights that would come from your role as the Definer.\n",
      "\n",
      "[Definitions]\n",
      "- \"Insights\": Short snippet of text which provides intelligent analysis, ideas, arguments, perspectives, questions to ask, deeper insights, etc. that will improve the current conversation. \"Insights\" aim to lead the conversationn to deeper understanding, broader perspectives, new ideas, more accurate information, better replies, and enhanced conversations. Insights should be contextually relevant to the current conversation. The \"Insight\" should be providing additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what has already been said.\n",
      "- \"Convoscope\": an intelligence augmentation tool running on user's smart glasses or on their laptop that they use during conversations to improve conversations. Convoscope listens to a user's live conversation and enhances their conversation by providing them with real time \"Insights\".\n",
      "\n",
      "[Your Expertise: Definer]\n",
      "\n",
      "As the Definer agent, you identify and explain specialized terms, concepts, and entities—including places, organizations, and notable individuals—in the conversation. Provide clarifications for jargon, ideas, and entities that might be unfamiliar to a layperson or to the user, while avoiding definitions of widely known terms and commonly recognized entities..\n",
      "\n",
      "[Your Tools]\n",
      "You have access to tools, which you should utilize to help you generate highly valuable, insightful, contextually relevant insights.\n",
      "\n",
      "Limit your usage of the Search_Engine tool to 1 times. Mention your number of usages of the tool in your thoughts.\n",
      "\n",
      "[Example Insights]\n",
      "Here are some example insights structure that you should aim to generate, a summary is given instead of the entire transcript for brevity. From these examples, you just need to learn how to structure a good insight:\n",
      "\n",
      "\n",
      "1. Conversation: Transcript mentions \"Higgs Boson.\"\n",
      "Insight: Higgs Boson: key particle in physics, explains mass origin.\n",
      "\n",
      "2. Conversation: Transcript mentions \"Blockchain technology.\"\n",
      "Insight: Blockchain: decentralized ledger, powers cryptocurrencies like Bitcoin.\n",
      "\n",
      "3. Conversation: Transcript mentions \"Silicon Valley.\"\n",
      "Insight: Silicon Valley: CA's high-tech, innovation hub.\n",
      "\n",
      "4. Conversation: Transcript mentions \"The United Nations.\"\n",
      "Insight: UN: founded 1945, promotes global cooperation.\n",
      "\n",
      "\n",
      "[Previously Generated Insights]\n",
      "Here are some insights that had already been previously generated, if any, for this conversation. You should not repeat any of these insights:\n",
      "\n",
      "\n",
      "\n",
      "[Your Task]\n",
      "<Task start>\n",
      "It's now time to generate an \"Insight\" for the following conversation transcript. The \"Insight\" should provide additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what is being said in the transcripts. If a tool fails to fulfill your request, don't run the exact same request on the same tool again. Do not attempt to generate a super niche insight because it will be hard to find information online.\n",
      "\n",
      "In your initial thought, you should first come up with a plan to generate the \"Insight\". The plan should include:\n",
      "\n",
      "1. Scan the conversation for specialized terms, concepts, and entities that are not widely known or might be unfamiliar to the user.\n",
      "2. Provide clear, concise definitions or explanations for these terms, concepts, and entities. If you need to search using the Internet, wikipedia is useful for entities and urban dictionary for jargons. If a definition has multiple meanings, define the one relevant to the transcript.\n",
      "3. Verify if the definitions are short and relevant, shorten it if it is too long, return \"null\" if it is not relevant.\n",
      "\n",
      "The plan should include a final step to generate the insight. The \"Insight\" must 9 words or less. The \"Insight\" can omit filler words or replace words with symbols or acronyms to shorten its length where possible. If you don't have a very valuable and useful \"Insight\" for any reason, simply specify your \"Insight\" as the string \"null\". \n",
      "\n",
      "Once you have the \"Insight\", extract the url of the most relevant reference source used to generate this \"Insight\". Also, relay the motive of the why the insight benefits the conversation, with quotes from the transcript. If the \"Insight\" is not up to par with the examples, we should hide it and just return \"null\" for the \"Insight\".\n",
      "\n",
      "Here are more detailed formatting instructions\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Query for an insight generation process\", \"properties\": {\"agent_insight\": {\"title\": \"Agent Insight\", \"description\": \"the short insight generated by the agent\", \"type\": \"string\"}, \"reference_source\": {\"title\": \"Reference Source\", \"description\": \"the most useful source used to generate this insight\", \"default\": \"\", \"type\": \"string\"}, \"insight_motive\": {\"title\": \"Insight Motive\", \"description\": \"short motive of why the insight was generated, quoting the text in the transcript\", \"type\": \"string\"}}, \"required\": [\"agent_insight\", \"insight_motive\"]}\n",
      "```\n",
      "\n",
      "Remember, the insight needs to be 9 words or less!\n",
      "<Task end>\n",
      "\n",
      "[Input Transcript]\n",
      "<Transcript start> And I think the perspectival knowing has a lot to do with the adverbial qualia. Adjectival qualia and adverbial qualia. I'm learning so many new things today. Okay, so that's another way of knowing. Right, the perspectival, and then there's a deeper one. And this is a philosophical point, and I don't want to, we can go through the argument, but you don't have to know that you know in order to know, because if you start doing that,, you get an infinite regress. There has to be kinds of knowing that doesn't mean you know that you know that. Yeah. Okay. Of course. Okay, great. Okay, good. Well, there was a lot of ink spilled over that over a 40 year period, so. My philosophers, they spill, this is what they do, they spill ink to get paid for ink spillage. So I want to talk about what I call participatory knowing., This is the idea that you and the world are co participating in things and such that real affordances exist between you. So both me and this environment are shaped by gravity, so the affordance of walking becomes available to me. Both me and a lot of this environment are shaped by my biology, and so affordances for, that are here. Look at this cup, shared physics, shared sort of biological factors, my hand, I'm bipedal, also culture is shaping me and shaping this. I had to learn how to use that and treat it as a cup. So this is an agent arena relationship, right?, Use identities being created in your agency, identities being created in the world as an arena so you and the world fit together. You know when that's missing, when you're really lonely, or you're homesick, or you're suffering culture shock. So this is participatory knowing, and it's the sense of, it comes with a sense of belonging.\n",
      " At every level. So the ability to walk is a kind of knowing. Yes. Yes. That there's a dance between the physics that enables this process and just participating in the process is the act of knowing. Right. And there's a really weird form of memory you have for this kind of knowing, it's called<Transcript end>\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kenji/Convoscope/server/tests/Generate-Insights-master-worker-demo.ipynb Cell 24\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/kenji/Convoscope/server/tests/Generate-Insights-master-worker-demo.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m agent_prompt \u001b[39m=\u001b[39m expert_agent_prompt_maker(agent_key, test_transcript, [])\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/kenji/Convoscope/server/tests/Generate-Insights-master-worker-demo.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(agent_prompt)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/kenji/Convoscope/server/tests/Generate-Insights-master-worker-demo.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m agent\u001b[39m.\u001b[39;49mrun(agent_prompt)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chains/base.py:503\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    502\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 503\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    504\u001b[0m         _output_key\n\u001b[1;32m    505\u001b[0m     ]\n\u001b[1;32m    507\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    508\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    509\u001b[0m         _output_key\n\u001b[1;32m    510\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chains/base.py:308\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    307\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 308\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    309\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    310\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    311\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    312\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chains/base.py:302\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    295\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    296\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    297\u001b[0m     inputs,\n\u001b[1;32m    298\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    299\u001b[0m )\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 302\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    303\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    304\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    307\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/agents/agent.py:1141\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1141\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m   1142\u001b[0m         name_to_tool_map,\n\u001b[1;32m   1143\u001b[0m         color_mapping,\n\u001b[1;32m   1144\u001b[0m         inputs,\n\u001b[1;32m   1145\u001b[0m         intermediate_steps,\n\u001b[1;32m   1146\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m   1147\u001b[0m     )\n\u001b[1;32m   1148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1149\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m   1150\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m   1151\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/agents/agent.py:928\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    925\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m    927\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 928\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[1;32m    929\u001b[0m         intermediate_steps,\n\u001b[1;32m    930\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    931\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[1;32m    932\u001b[0m     )\n\u001b[1;32m    933\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/agents/agent.py:541\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \n\u001b[1;32m    531\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[39m    Action specifying what tool to use.\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    540\u001b[0m full_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 541\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfull_inputs)\n\u001b[1;32m    542\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_parser\u001b[39m.\u001b[39mparse(full_output)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chains/llm.py:257\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    243\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chains/base.py:308\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    307\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 308\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    309\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    310\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    311\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    312\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chains/base.py:302\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    295\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    296\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    297\u001b[0m     inputs,\n\u001b[1;32m    298\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    299\u001b[0m )\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 302\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    303\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    304\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    307\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chains/llm.py:93\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m     89\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     90\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m     91\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     92\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 93\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m     94\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chains/llm.py:103\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    104\u001b[0m     prompts,\n\u001b[1;32m    105\u001b[0m     stop,\n\u001b[1;32m    106\u001b[0m     callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    107\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[1;32m    108\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chat_models/base.py:465\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    458\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    459\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    463\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    464\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 465\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chat_models/base.py:355\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[1;32m    354\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 355\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    356\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    357\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[1;32m    358\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[1;32m    359\u001b[0m ]\n\u001b[1;32m    360\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chat_models/base.py:345\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[1;32m    343\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 345\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[1;32m    346\u001b[0m                 m,\n\u001b[1;32m    347\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    348\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    349\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    350\u001b[0m             )\n\u001b[1;32m    351\u001b[0m         )\n\u001b[1;32m    352\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    353\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chat_models/base.py:497\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    494\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m     )\n\u001b[1;32m    496\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 497\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    498\u001b[0m         messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    499\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    501\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chat_models/openai.py:360\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    359\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[0;32m--> 360\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(\n\u001b[1;32m    361\u001b[0m     messages\u001b[39m=\u001b[39;49mmessage_dicts, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    362\u001b[0m )\n\u001b[1;32m    363\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chat_models/openai.py:299\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/langchain/chat_models/openai.py:297\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/openai/api_requestor.py:289\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[1;32m    292\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    293\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    294\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    295\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    296\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[1;32m    299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/openai/api_requestor.py:606\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    604\u001b[0m     _thread_context\u001b[39m.\u001b[39msession_create_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    605\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 606\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    607\u001b[0m         method,\n\u001b[1;32m    608\u001b[0m         abs_url,\n\u001b[1;32m    609\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    610\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    611\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    612\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    613\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    614\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    615\u001b[0m     )\n\u001b[1;32m    616\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    617\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1379\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1312\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent_key = expert_agent_config_list[\"Definer\"]\n",
    "# agent_key = expert_agent_config_list[\"Statistician\"]\n",
    "agent_prompt = expert_agent_prompt_maker(agent_key, test_transcript, [])\n",
    "print(agent_prompt)\n",
    "agent.run(agent_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definer Agent\n",
    "- If we include it as part of the original pipeline, it is too slow, defines one at a time, can batch but it breaks the structure of other insights, and search is harder with batching\n",
    "- Do we need all definitions to have links?\n",
    "- Another process to detect rare words and then pass them to a single definer agent pipeline will be a lot faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1 of rare entity recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# proactively decides which agents to run and runs them\n",
    "proactive_rare_word_agent_prompt_blueprint = \"\"\"\n",
    "[Your Objective]\n",
    "You are a \"Rare Terms Identifier\", your role is to enhance conversations by identifying \"Rare Terms\" are specialized words, concepts, jargons, and entities, including philosophical, scientific, medical, and cultural references, that are significant within their domain but not widely known or understood in general discourse, but could be significant to the conversation's depth and understanding. \n",
    "\n",
    "You are given a live stream of conversation transcripts, your goal is to implicitly detect the goal of the conversation and then identify \"Rare Terms\" that participants are likely unfamiliar with and would benefit from learning about. \n",
    "\n",
    "[Rare Term Identification Criteria]\n",
    "- \"Rare Terms\" should be no more than 3 words long.\n",
    "- Do not select \"Rare Terms\" that are based on personal opinions, beliefs, or values. \"Rare Terms\" should be easily found on Wikipedia, backed by a source.\n",
    "- If a \"Rare Term\" is already defined in the transcript, then don't select it.\n",
    "- If a \"Rare Term\" does not have a standalone definition, then don't select it.\n",
    "\n",
    "When selecting a \"Rare Term\" from potential ones, you should consider the following criterias:\n",
    "- Rarity: The \"Rare Term\" must not be commonly known to the general public, it must be really niched or rarely known. For example, \"Bhutan\" is rarely known place as there isn't much news about it, but entities like \"Harvard\" and \"The Olympics\" are already really well known and internationally covered. Concepts and jargons are considered rare as well especially if they are niche terms used in a specific field.\n",
    "- Complexity: The \"Rare Term\" must have a meaning that is not immediately apparent from its constituent words, or be based on combinations of adjectives added onto a noun. For example, \"Negative effects\" and \"Oxford lecture theatre\" are simple to understand and not worth defining. The term should involve a concept or idea that transcends the literal interpretation of the words, such as \"Butterfly Effect\".\n",
    "- Specificity: The \"Rare Term\" must be able to be clearly defined, concise and specific. We don't want to select ambiguous or broad terms that are hard to define, like \"The meaning of life\" or \"Stephen Wolfram's work\".\n",
    "- Searchability: The \"Rare Term\" must be easily searchable on the Internet and have a wikipedia page. Since you are already trained on a lot of Internet data, if you don't think the \"Rare Term\" has a wikipedia page, then don't select it.\n",
    "- Relevance: The \"Rare Term\" must have the potential to significantly enhance and provide value to the conversation's depth or understanding. For example, if the conversation is about AI, then we want to emphasize more definitions on AI specific \"Rare Terms\".\n",
    "\n",
    "We want to select \"Rare Terms\" that are rare, complex, searchable, and relevant.\n",
    "\n",
    "[Additional Rules]\n",
    "- For \"Rare Terms\" that could be easily misunderstood without the context, you can add in a hint to make it more easily searchable. Like adding its entity type as a hint.\n",
    "- For \"Rare Terms\" that are abbreviations of a name, like \"Hinton\", expand it based on the conversation context, like \"Geoffrey Hinton\" if you are confident so we have more context, otherwise leave it out.\n",
    "- For \"Rare Terms\" that are not spelled well, or phrased well but you are confident in what the \"Rare Term\" is implying, you can add in a hint to the \"Rare Term\" so that it is easy to search online. For example, you detect \"Classic seven plots\" but you know that it is implying the book \"The Seven Basic Plots\", then you should expand the term to \"Classic seven plots - The Seven Basic Plots\".\n",
    "- For \"Rare Terms\" that are standalone acronyms, we can add in a hint for easier searchability. For example, \"UFC\" could be expanded to \"UFC - Ultimate Fighting Championship\". \n",
    "\n",
    "[Conversation Transcript]\n",
    "Here is the current live transcript of the conversation you're monitoring:\n",
    "<Transcript start>{conversation_context}<Transcript end>\n",
    "\n",
    "[Recent Definition History]\n",
    "Here are the recent definitions that have already been defined. There is no need to define the same entity again:\n",
    "{definitions_history}\n",
    "\n",
    "<Task start>\n",
    "Based on the criteria, output an array of strings, each representing a \"Rare Term\" detected in the conversation. If no relevant entities are identified, output an empty array. {format_instructions}\n",
    "<Task end>\n",
    "\"\"\"\n",
    "\n",
    "# , but they're expensive to run, so only specify agents that will be helpful\n",
    "\n",
    "\n",
    "def run_proactive_rare_word_agent_and_definer(\n",
    "    conversation_context: str, definitions_history: list = []\n",
    "):\n",
    "    # run proactive agent to find out which expert agents we should run\n",
    "    proactive_rare_word_agent_response = run_proactive_rare_word_agent(\n",
    "        conversation_context, definitions_history\n",
    "    )\n",
    "\n",
    "    # do nothing else if proactive meta agent didn't specify an agent to run\n",
    "    if proactive_rare_word_agent_response == []:\n",
    "        return []\n",
    "\n",
    "    # pass words to define to definer agent\n",
    "    print(\"proactive_rare_word_agent_response\", proactive_rare_word_agent_response)\n",
    "    pass\n",
    "\n",
    "    # # get the configs of any expert agents we should run\n",
    "    # experts_to_run_configs = list()\n",
    "    # for expert_to_run in proactive_rare_word_agent_response:\n",
    "    #     experts_to_run_configs.append(expert_agent_config_list[expert_to_run])\n",
    "\n",
    "    # # run all the agents in parralel\n",
    "    # loop = asyncio.get_event_loop()\n",
    "    # agents_to_run_tasks = [\n",
    "    #     expert_agent_arun_wrapper(\n",
    "    #         expert_agent_config,\n",
    "    #         conversation_context,\n",
    "    #         definitions_history,\n",
    "    #     )\n",
    "    #     for expert_agent_config in experts_to_run_configs\n",
    "    # ]\n",
    "    # insights_tasks = asyncio.gather(*agents_to_run_tasks)\n",
    "    # insights = loop.run_until_complete(insights_tasks)\n",
    "    # return insights\n",
    "\n",
    "\n",
    "class ProactiveRareWordAgentQuery(BaseModel):\n",
    "    \"\"\"\n",
    "    Proactive rare word agent that identifies rare terms in a conversation context\n",
    "    \"\"\"\n",
    "\n",
    "    to_define_list: list = Field(\n",
    "        description=\"the rare terms to define\",\n",
    "    )\n",
    "\n",
    "\n",
    "proactive_rare_word_agent_query_parser = PydanticOutputParser(\n",
    "    pydantic_object=ProactiveRareWordAgentQuery\n",
    ")\n",
    "\n",
    "\n",
    "def run_proactive_rare_word_agent(conversation_context: str, definitions_history: list):\n",
    "    # start up GPT4 connection\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0.2,\n",
    "        openai_api_key=os.environ.get(\"OPEN_AI_API_KEY\"),\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "    )\n",
    "\n",
    "    extract_proactive_rare_word_agent_query_prompt = PromptTemplate(\n",
    "        template=proactive_rare_word_agent_prompt_blueprint,\n",
    "        input_variables=[\n",
    "            \"conversation_context\",\n",
    "            \"definitions_history\",\n",
    "        ],\n",
    "        partial_variables={\n",
    "            \"format_instructions\": proactive_rare_word_agent_query_parser.get_format_instructions()\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if len(definitions_history) > 0:\n",
    "        definitions_history = format_list_data(definitions_history)\n",
    "    else:\n",
    "        definitions_history = \"None\"\n",
    "\n",
    "    proactive_rare_word_agent_query_prompt_string = (\n",
    "        extract_proactive_rare_word_agent_query_prompt.format_prompt(\n",
    "            conversation_context=conversation_context,\n",
    "            definitions_history=definitions_history,\n",
    "        ).to_string()\n",
    "    )\n",
    "\n",
    "    # print(\"Proactive meta agent query prompt string\", proactive_rare_word_agent_query_prompt_string)\n",
    "\n",
    "    response = llm(\n",
    "        [HumanMessage(content=proactive_rare_word_agent_query_prompt_string)]\n",
    "    )\n",
    "    try:\n",
    "        definitions_to_define_list = proactive_rare_word_agent_query_parser.parse(\n",
    "            response.content\n",
    "        ).to_define_list\n",
    "        return definitions_to_define_list\n",
    "    except OutputParserException:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2 \n",
    "We focus on the entities that are easy to define and have wikipedia pages because old results keep on outputting entities that are hard to define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# proactively decides which agents to run and runs them\n",
    "proactive_rare_word_agent_prompt_blueprint = \"\"\"\n",
    "# Objective: \n",
    "As a \"Rare Entities Identifier,\" your role is to enhance conversations by detecting and identifying \"Rare entities.\" These are specialized words, concepts, jargons, and entities (people, places, organizations, objects, events), and also including philosophical, scientific, medical, and cultural references that are significant within their domain but not widely known or understood in general discourse.\n",
    "\n",
    "# Rare Term Identification Criteria\n",
    "- Length Constraint: \"Rare Entities\" should be no more than 3 words long.\n",
    "- Objective Nature: Select entities that are factual and can be found on Wikipedia, not based on personal opinions, beliefs, or values.\n",
    "- Avoid Redundancy: If a \"Rare Entity\" is already defined in the transcript, do not select it again.\n",
    "- Standalone Definition: Choose entities that have a clear, independent definition.\n",
    "\n",
    "# Selection Criteria for 'Rare Entities'\n",
    "- Rarity: Pick entities that are really not well known or niche in a field, such as \"Bhutan\", \"Parkinson's Law\", \"Implementation Intention\" etc as opposed to widely recognized entities like \"Harvard\" and \"The Olympics\"\n",
    "- Complexity and Specificity: The term's meaning should be non-obvious and not represent a broad category. For example, \"Butterfly Effect\" is complex and specific, while \"Negative effects\" and \"Oxford lecture theatre\" are straightforward.\n",
    "- Definability: Ensure the term can be defined succinctly and clearly, you must avoid entities that are too broad or require extensive background explanation.\n",
    "- Searchability: The rare entity should be easily searchable online and have its own Wikipedia page. The \"rare entity\" will be used as a wikipedia search term so only include it if you are confident it has a Wikipedia page.\n",
    "- Relevance: The term should meaningfully enhance the conversation's depth, appropriate to the context, such as AI-specific entities in a discussion about AI.\n",
    "\n",
    "We only want to select \"Rare entities\" that are rare, complex, easy to define, relevant, and most importantly have a wikipedia page.\n",
    "\n",
    "# Additional Rules\n",
    "- Contextual Hints: Add hints for clarity, like entity types or expanded abbreviations (e.g., \"Geoffrey Hinton\" instead of just \"Hinton\").\n",
    "- Correction for Clarity: Adjust poorly spelled or phrased entities for accuracy (e.g., \"Classic seven plots - The Seven Basic Plots\").\n",
    "- Acronym Expansion: For standalone acronyms, provide full forms for clarity (e.g., \"UFC - Ultimate Fighting Championship\").\n",
    "\n",
    "# Conversation Transcript:\n",
    "<Transcript start>{conversation_context}<Transcript end>\n",
    "\n",
    "# Recent Definition History:\n",
    "Here are the recent definitions that have already been defined:\n",
    "{definitions_history}\n",
    "\n",
    "# Task:\n",
    "Based on the criteria, output an array of strings, each representing a \"Rare Term\" detected in the conversation, that can be used as a wikipedia search term and are likely to lead to wikipedia results. If no relevant entities are identified, output an empty array. {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "# , but they're expensive to run, so only specify agents that will be helpful\n",
    "\n",
    "\n",
    "def run_proactive_rare_word_agent_and_definer(\n",
    "    conversation_context: str, definitions_history: list = []\n",
    "):\n",
    "    # run proactive agent to find out which expert agents we should run\n",
    "    proactive_rare_word_agent_response = run_proactive_rare_word_agent(\n",
    "        conversation_context, definitions_history\n",
    "    )\n",
    "\n",
    "    # do nothing else if proactive meta agent didn't specify an agent to run\n",
    "    if proactive_rare_word_agent_response == []:\n",
    "        return []\n",
    "\n",
    "    # pass words to define to definer agent\n",
    "    print(\"proactive_rare_word_agent_response\", proactive_rare_word_agent_response)\n",
    "    pass\n",
    "\n",
    "    # # get the configs of any expert agents we should run\n",
    "    # experts_to_run_configs = list()\n",
    "    # for expert_to_run in proactive_rare_word_agent_response:\n",
    "    #     experts_to_run_configs.append(expert_agent_config_list[expert_to_run])\n",
    "\n",
    "    # # run all the agents in parralel\n",
    "    # loop = asyncio.get_event_loop()\n",
    "    # agents_to_run_tasks = [\n",
    "    #     expert_agent_arun_wrapper(\n",
    "    #         expert_agent_config,\n",
    "    #         conversation_context,\n",
    "    #         definitions_history,\n",
    "    #     )\n",
    "    #     for expert_agent_config in experts_to_run_configs\n",
    "    # ]\n",
    "    # insights_tasks = asyncio.gather(*agents_to_run_tasks)\n",
    "    # insights = loop.run_until_complete(insights_tasks)\n",
    "    # return insights\n",
    "\n",
    "\n",
    "class ProactiveRareWordAgentQuery(BaseModel):\n",
    "    \"\"\"\n",
    "    Proactive rare word agent that identifies rare entities in a conversation context\n",
    "    \"\"\"\n",
    "\n",
    "    to_define_list: list = Field(\n",
    "        description=\"the rare entities to define\",\n",
    "    )\n",
    "\n",
    "\n",
    "proactive_rare_word_agent_query_parser = PydanticOutputParser(\n",
    "    pydantic_object=ProactiveRareWordAgentQuery\n",
    ")\n",
    "\n",
    "\n",
    "def run_proactive_rare_word_agent(conversation_context: str, definitions_history: list):\n",
    "    # start up GPT4 connection\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        openai_api_key=os.environ.get(\"OPEN_AI_API_KEY\"),\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "    )\n",
    "\n",
    "    extract_proactive_rare_word_agent_query_prompt = PromptTemplate(\n",
    "        template=proactive_rare_word_agent_prompt_blueprint,\n",
    "        input_variables=[\n",
    "            \"conversation_context\",\n",
    "            \"definitions_history\",\n",
    "        ],\n",
    "        partial_variables={\n",
    "            \"format_instructions\": proactive_rare_word_agent_query_parser.get_format_instructions()\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if len(definitions_history) > 0:\n",
    "        definitions_history = format_list_data(definitions_history)\n",
    "    else:\n",
    "        definitions_history = \"None\"\n",
    "\n",
    "    proactive_rare_word_agent_query_prompt_string = (\n",
    "        extract_proactive_rare_word_agent_query_prompt.format_prompt(\n",
    "            conversation_context=conversation_context,\n",
    "            definitions_history=definitions_history,\n",
    "        ).to_string()\n",
    "    )\n",
    "\n",
    "    # print(\"Proactive meta agent query prompt string\", proactive_rare_word_agent_query_prompt_string)\n",
    "\n",
    "    response = llm(\n",
    "        [HumanMessage(content=proactive_rare_word_agent_query_prompt_string)]\n",
    "    )\n",
    "    try:\n",
    "        definitions_to_define_list = proactive_rare_word_agent_query_parser.parse(\n",
    "            response.content\n",
    "        ).to_define_list\n",
    "        return definitions_to_define_list\n",
    "    except OutputParserException:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " And for the first time I got feedback from people who I respected saying, no, like don't write code like this. Now, of course, just getting that feedback is not enough. The way that I really got good was I wanted to write this thing like that could emulate and then visualize, like arm binaries. Cause I wanted to hack the iPhone better. And I didn't like that I couldn't like see what the, I couldn't single step through the processor because I had no debugger on there, especially for the low level things like the boot rum and the bootloader. So I tried to build this tool to do it. And I built the tool once and it was terrible. I built the tool a second time, it was terrible. I built the tool a third time. This was by the time I was at Facebook, it was kind of okay., And then I built the tool a fourth time when I was a Google intern again in 2014. And that was the first time I was like, this is finally usable. How do you pronounce this Kira? Kira, yeah. So it's essentially the most efficient way to visualize the change of state of the computer as the program is running. That's what you mean by debugger. Yeah, it's a timeless debugger., So you can rewind just as easily as going forward. Think about if you're using GDB, you have to put a watch on a variable. If you wanna see if that variable changes. In Kira, you can just click on that variable and then it shows every single time when that variable was changed or accessed. Think about it like Git for your computers, the run log. So there's like a deep log of the state of the computer, as the program runs and you can rewind. Why isn't that, maybe it is, maybe you can educate me. Why isn't that kind of debugging used more often? Cause the tooling's bad. Well, two things. One, if you're trying to debug Chrome, Chrome is a 200 megabyte binary that runs slowly on desktops. So that's gonna be really hard to use for that.\n",
      " But it's really good to use for like CTFs and for boot roms and for small parts of code. So it's hard if you're trying to debug like massive systems. What's a CTF and what's a boot rom? A boot rom is the first code that executes the minute you give power to your iPhone. Okay. And CTF where these competitions that I played capture the flag. Capture the flag, I was gonna ask you about that. What are those, look at,\n",
      "proactive_rare_word_agent_response ['arm binaries - Machine code for ARM architecture', 'boot rom - Initial code run by an iPhone on startup', 'CTF - Competitive hacking event, Capture The Flag', 'GDB - GNU Debugger for debugging programs', 'Kira - Time-traveling debugger software']\n"
     ]
    }
   ],
   "source": [
    "test_transcript = generate_test_input()\n",
    "print(test_transcript)\n",
    "res = run_proactive_rare_word_agent_and_definer(test_transcript, [])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Engine tool for definer agent\n",
    "- Takes in a list of keywords to create definitions for\n",
    "- We want to check if we have the definition in the cache somewhere\n",
    "    - If there is, we just save into db for display\n",
    "- If not we pass it to another LLM chain to search for info\n",
    "    - We build a custom search tool that can take in multiple keywords\n",
    "    - the LLM defines the definitions\n",
    "    - Another LLM checks if they are relevant and useful for the conversation\n",
    "- We just want 1 quick search without summary, just using serp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/kenji/Convoscope/server/tests/Generate-Insights-master-worker-demo.ipynb Cell 32\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/kenji/Convoscope/server/tests/Generate-Insights-master-worker-demo.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m         \u001b[39mprint\u001b[39m(result)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/kenji/Convoscope/server/tests/Generate-Insights-master-worker-demo.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m# Run the main function if you want to test the code\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/kenji/Convoscope/server/tests/Generate-Insights-master-worker-demo.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m asyncio\u001b[39m.\u001b[39;49mrun(main())\n",
      "File \u001b[0;32m~/miniforge3/envs/tosg/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[39mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[39mwith\u001b[39;00m Runner(debug\u001b[39m=\u001b[39mdebug) \u001b[39mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[39mreturn\u001b[39;00m runner\u001b[39m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "# Search tool\n",
    "from typing import Any, List, Literal\n",
    "import requests\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "k: int = 5\n",
    "gl: str = \"us\"\n",
    "hl: str = \"en\"\n",
    "tbs = None\n",
    "num_sentences = 7\n",
    "serper_api_key = os.environ.get(\"SERPER_API_KEY\")\n",
    "search_type: Literal[\"news\", \"search\", \"places\", \"images\"] = \"search\"\n",
    "\n",
    "\n",
    "async def serper_search(search_term: str, search_type: str = \"search\", **kwargs: Any) -> dict:\n",
    "    headers = {\n",
    "        \"X-API-KEY\": serper_api_key or \"\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": search_term,\n",
    "        **{key: value for key, value in kwargs.items() if value is not None},\n",
    "    }\n",
    "    response = requests.post(\n",
    "        f\"https://google.serper.dev/{search_type}\", headers=headers, params=params\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "    return search_results\n",
    "\n",
    "\n",
    "async def parse_snippets(search_term: str, results: dict) -> str:\n",
    "    result_key_for_type = {\n",
    "        \"news\": \"news\",\n",
    "        \"places\": \"places\",\n",
    "        \"images\": \"images\",\n",
    "        \"search\": \"organic\",\n",
    "    }\n",
    "    snippets = [f\"{search_term} got results: \"]\n",
    "\n",
    "    # Add the answer box if present\n",
    "    if results.get(\"answerBox\"):\n",
    "        answer_box = results.get(\"answerBox\", {})\n",
    "        answer = answer_box.get(\"answer\") or answer_box.get(\"snippet\") or answer_box.get(\"snippetHighlighted\")\n",
    "        if answer:\n",
    "            snippets.append(f\"Answer Box: {answer}\")\n",
    "\n",
    "    # Add top k search results\n",
    "    for result in results[result_key_for_type[search_type]][:k]:\n",
    "        snippet = result.get(\"snippet\")\n",
    "        snippets.append(snippet)\n",
    "\n",
    "    return '\\n'.join(snippets)\n",
    "\n",
    "\n",
    "async def custom_search(search_terms: List[str], **kwargs: Any) -> List[str]:\n",
    "    tasks = []\n",
    "    for search_term in search_terms:\n",
    "        task = asyncio.create_task(serper_search(search_term, **kwargs))\n",
    "        tasks.append(task)\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return [await parse_snippets(term, result) for term, result in zip(search_terms, results)]\n",
    "\n",
    "\n",
    "# Example of how to use the modified function\n",
    "async def main():\n",
    "    search_terms = [\"Python\", \"OpenAI\"]\n",
    "    results = await custom_search(search_terms)\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "# Run the main function if you want to test the code\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 3: Define the rare entities right away\n",
    "This is surprisingly more efficient, but take up a lot of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# proactively decides which agents to run and runs them\n",
    "proactive_rare_word_agent_prompt_blueprint = \"\"\"\n",
    "# Objective: \n",
    "As a \"Rare Entities Identifier,\" your role is to enhance conversations by detecting and identifying \"Rare entities.\" These are specialized words, concepts, jargons, and entities (people, places, organizations, objects, events), and also including philosophical, scientific, medical, and cultural references that are significant within their domain but not widely known or understood in general discourse.\n",
    "\n",
    "# Rare Term Identification Criteria\n",
    "- Length Constraint: \"Rare Entities\" should be no more than 3 words long.\n",
    "- Objective Nature: Select entities that are factual and can be found on Wikipedia, not based on personal opinions, beliefs, or values.\n",
    "- Avoid Redundancy: If a \"Rare Entity\" is already defined in the transcript, do not select it again.\n",
    "- Standalone Definition: Choose entities that have a clear, independent definition.\n",
    "\n",
    "# Selection Criteria for 'Rare Entities'\n",
    "- Rarity: Pick entities that are really not well known or niche in a field, such as \"Bhutan\", \"Parkinson's Law\", \"Implementation Intention\" etc as opposed to widely recognized entities like \"Harvard\" and \"The Olympics\"\n",
    "- Complexity and Specificity: The term's meaning should be non-obvious and not represent a broad category. For example, \"Butterfly Effect\" is complex and specific, while \"Negative effects\" and \"Oxford lecture theatre\" are straightforward.\n",
    "- Definability: Ensure the term can be defined succinctly and clearly, you must avoid entities that are too broad or require extensive background explanation.\n",
    "- Searchability: The rare entity should be easily searchable online and have its own Wikipedia page. The \"rare entity\" will be used as a wikipedia search term so only include it if you are confident it has a Wikipedia page.\n",
    "- Relevance: The term should meaningfully enhance the conversation's depth, appropriate to the context, such as AI-specific entities in a discussion about AI.\n",
    "\n",
    "We only want to select \"Rare entities\" that are rare, complex, easy to define, relevant, and most importantly have a wikipedia page.\n",
    "\n",
    "# Additional Rules\n",
    "- Contextual Hints: Add hints for clarity, like entity types or expanded abbreviations (e.g., \"Geoffrey Hinton\" instead of just \"Hinton\").\n",
    "- Correction for Clarity: Adjust poorly spelled or phrased entities for accuracy (e.g., \"Classic seven plots - The Seven Basic Plots\").\n",
    "- Acronym Expansion: For standalone acronyms, provide full forms for clarity (e.g., \"UFC - Ultimate Fighting Championship\").\n",
    "\n",
    "# Conversation Transcript:\n",
    "<Transcript start>{conversation_context}<Transcript end>\n",
    "\n",
    "# Recent Definition History:\n",
    "Here are the recent definitions that have already been defined:\n",
    "{definitions_history}\n",
    "\n",
    "# Task:\n",
    "Based on the criteria, output an array of strings, each representing the definition of a \"rare entity\" in less than 10 words as concise as possible. If no relevant entities are identified, output an empty array. {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "# , but they're expensive to run, so only specify agents that will be helpful\n",
    "\n",
    "\n",
    "def run_proactive_rare_word_agent_and_definer(\n",
    "    conversation_context: str, definitions_history: list = []\n",
    "):\n",
    "    # run proactive agent to find out which expert agents we should run\n",
    "    proactive_rare_word_agent_response = run_proactive_rare_word_agent(\n",
    "        conversation_context, definitions_history\n",
    "    )\n",
    "\n",
    "    # do nothing else if proactive meta agent didn't specify an agent to run\n",
    "    if proactive_rare_word_agent_response == []:\n",
    "        return []\n",
    "\n",
    "    # pass words to define to definer agent\n",
    "    print(\"proactive_rare_word_agent_response\", proactive_rare_word_agent_response)\n",
    "    pass\n",
    "\n",
    "    # # get the configs of any expert agents we should run\n",
    "    # experts_to_run_configs = list()\n",
    "    # for expert_to_run in proactive_rare_word_agent_response:\n",
    "    #     experts_to_run_configs.append(expert_agent_config_list[expert_to_run])\n",
    "\n",
    "    # # run all the agents in parralel\n",
    "    # loop = asyncio.get_event_loop()\n",
    "    # agents_to_run_tasks = [\n",
    "    #     expert_agent_arun_wrapper(\n",
    "    #         expert_agent_config,\n",
    "    #         conversation_context,\n",
    "    #         definitions_history,\n",
    "    #     )\n",
    "    #     for expert_agent_config in experts_to_run_configs\n",
    "    # ]\n",
    "    # insights_tasks = asyncio.gather(*agents_to_run_tasks)\n",
    "    # insights = loop.run_until_complete(insights_tasks)\n",
    "    # return insights\n",
    "\n",
    "\n",
    "class ProactiveRareWordAgentQuery(BaseModel):\n",
    "    \"\"\"\n",
    "    Proactive rare word agent that identifies rare entities in a conversation context\n",
    "    \"\"\"\n",
    "\n",
    "    to_define_list: list = Field(\n",
    "        description=\"the rare entities to define\",\n",
    "    )\n",
    "\n",
    "\n",
    "proactive_rare_word_agent_query_parser = PydanticOutputParser(\n",
    "    pydantic_object=ProactiveRareWordAgentQuery\n",
    ")\n",
    "\n",
    "\n",
    "def run_proactive_rare_word_agent(conversation_context: str, definitions_history: list):\n",
    "    # start up GPT4 connection\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        openai_api_key=os.environ.get(\"OPEN_AI_API_KEY\"),\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "    )\n",
    "\n",
    "    extract_proactive_rare_word_agent_query_prompt = PromptTemplate(\n",
    "        template=proactive_rare_word_agent_prompt_blueprint,\n",
    "        input_variables=[\n",
    "            \"conversation_context\",\n",
    "            \"definitions_history\",\n",
    "        ],\n",
    "        partial_variables={\n",
    "            \"format_instructions\": proactive_rare_word_agent_query_parser.get_format_instructions()\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if len(definitions_history) > 0:\n",
    "        definitions_history = format_list_data(definitions_history)\n",
    "    else:\n",
    "        definitions_history = \"None\"\n",
    "\n",
    "    proactive_rare_word_agent_query_prompt_string = (\n",
    "        extract_proactive_rare_word_agent_query_prompt.format_prompt(\n",
    "            conversation_context=conversation_context,\n",
    "            definitions_history=definitions_history,\n",
    "        ).to_string()\n",
    "    )\n",
    "\n",
    "    # print(\"Proactive meta agent query prompt string\", proactive_rare_word_agent_query_prompt_string)\n",
    "\n",
    "    response = llm(\n",
    "        [HumanMessage(content=proactive_rare_word_agent_query_prompt_string)]\n",
    "    )\n",
    "    try:\n",
    "        definitions_to_define_list = proactive_rare_word_agent_query_parser.parse(\n",
    "            response.content\n",
    "        ).to_define_list\n",
    "        return definitions_to_define_list\n",
    "    except OutputParserException:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Like Microsoft has been doing so much stuff at such breadth for such a long period of time that like being CTO like most of the time, my job is very, very serious. And sometimes like I get caught up in like how amazing it is to be able to have the conversations that I have with the people, I get to have them with. Yeah, to reach back into the sentimental. And what's the radical markets and the economics? So the idea with radical markets is like, can you come up with new market based mechanisms to, you know, I think we have this,, we're having this debate right now, like does capitalism work like free markets work? Can the incentive structures that are built into these systems produce outcomes that are creating sort of equitably distributed benefits for every member of society?, You know, and I think it's a reasonable, reasonable set of questions to be asking. And so what Glenn, and so like, you know, one mode of thought there, like if you have doubts that the markets are actually working, you can sort of like tip towards like, okay, let's become more socialist and, you know, like have central planning and, you know, governments or some other central organization is like making a bunch of decisions, about how, you know, sort of work gets done and, you know, like where the, you know, where the investments and where the outputs of those investments get distributed. Glenn's notion is like, lean more into like the market based mechanism. So like, for instance, you know, this is one of the more radical ideas,\n",
      " like suppose that you had a radical pricing mechanism for assets like real estate where you were, you could be bid out of your position in your home, you know, for instance. So like if somebody came along and said,\n",
      "proactive_rare_word_agent_response ['CTO - Chief Technology Officer', 'Radical Markets - Economic theory for revamping market norms', \"Glenn Weyl - Economist, co-author of 'Radical Markets'\"]\n"
     ]
    }
   ],
   "source": [
    "test_transcript = generate_test_input()\n",
    "print(test_transcript)\n",
    "res = run_proactive_rare_word_agent_and_definer(test_transcript, [])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
